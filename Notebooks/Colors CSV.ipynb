{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 743,
     "status": "ok",
     "timestamp": 1606504784726,
     "user": {
      "displayName": "Sarah Hernández Serrano",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhPu56UtRlNcYlVlUouF6yEgbR8E4j0MVtAhTnKayY=s64",
      "userId": "18255259528200381895"
     },
     "user_tz": 360
    },
    "id": "dQfE-I2zfZTd"
   },
   "outputs": [],
   "source": [
    "LOMA_LINDA = '/Users/sarah/Downloads/Rock Datasets/Loma Linda'\n",
    "INTERNET = '/Users/sarah/Downloads/Rock Datasets/Internet'\n",
    "ALL = '/Users/sarah/Downloads/Rock Datasets/All'\n",
    "\n",
    "LOMA_LINDA_CROP = '/Users/sarah/Downloads/Rock Datasets/Loma Linda Cropped'\n",
    "INTERNET_CROP = '/Users/sarah/Downloads/Rock Datasets/Internet Cropped'\n",
    "ALL_CROP = '/Users/sarah/Downloads/Rock Datasets/All Cropped'\n",
    "\n",
    "LL_DRIVE = '/content/drive/MyDrive/Sem VII/RP Investigación/selectedCroppedImagesAllClasses/train' #validate\n",
    "LL_CROP = '/content/drive/My Drive/Sem VII/RP Investigación/LL Rocks'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 638,
     "status": "ok",
     "timestamp": 1606504790239,
     "user": {
      "displayName": "Sarah Hernández Serrano",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhPu56UtRlNcYlVlUouF6yEgbR8E4j0MVtAhTnKayY=s64",
      "userId": "18255259528200381895"
     },
     "user_tz": 360
    },
    "id": "id3u80hCfZTx"
   },
   "outputs": [],
   "source": [
    "IMG_PATH = '/Users/sarah/Documents/Rocks copy/train'\n",
    "DIR = '/Users/sarah/Documents/Rocks copy/crop'\n",
    "CSV_DIR = '/content/drive/My Drive/Sem VII/RP Investigación/LL Rocks/last.csv'\n",
    "\n",
    "IMG_SIZE = (512, 512)\n",
    "CLUSTERS = 4\n",
    "images_per_type_to_plot = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jDKMs5e4fZUB"
   },
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "f3lJeJBGfZUE"
   },
   "outputs": [],
   "source": [
    "# Libraries\n",
    "import cv2, os\n",
    "from PIL import Image, ImageOps\n",
    "import numpy as np\n",
    "from itertools import repeat\n",
    "\n",
    "def load_images_from_folder(folder, size):\n",
    "    images = []\n",
    "    filenames = []\n",
    "    for filename in os.listdir(folder):\n",
    "        if(not filename.lower().endswith(('.png', '.jpg', '.jpeg', '.tiff', '.bmp', '.gif'))):\n",
    "            print(filename, 'removed')\n",
    "            continue\n",
    "        img = Image.open(os.path.join(folder,filename))\n",
    "        fit_and_resized_image = ImageOps.fit(img, size, Image.ANTIALIAS)\n",
    "        img = np.array(fit_and_resized_image)\n",
    "        img = img[...,:3]\n",
    "        if img is not None:\n",
    "            images.append(img)\n",
    "            filenames.append(filename)\n",
    "    return (images, filenames)\n",
    "\n",
    "def load_images_from_directory(path, size):\n",
    "    paths = os.listdir(path)\n",
    "    x = []; y = []; files = [];\n",
    "    for folder in paths:\n",
    "        if(os.path.isfile(folder)):\n",
    "            print(folder, 'removed')\n",
    "            continue\n",
    "        images, filenames = load_images_from_folder(os.path.join(path, folder), size)\n",
    "        lbls = list(repeat(folder, len(images)))\n",
    "        x.extend(images)\n",
    "        y.extend(lbls)\n",
    "        files.extend(filenames)\n",
    "    return (x, y, files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "pz256ntbfZUN"
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "def get_dominant_colors(cluster, centroids):\n",
    "    # Get the number of different clusters, create histogram, and normalize\n",
    "    labels = np.arange(0, len(np.unique(cluster.labels_)) + 1)\n",
    "    (hist, _) = np.histogram(cluster.labels_, bins = labels)\n",
    "    hist = hist.astype(\"float\"); hist /= hist.sum()\n",
    "    \n",
    "    features = []\n",
    "    \n",
    "    colors = sorted([(percent, color) for (percent, color) in zip(hist, centroids)])\n",
    "    \n",
    "    for (percent, color) in colors:\n",
    "        features.extend(color)\n",
    "        features.append(percent)\n",
    "\n",
    "    return features\n",
    "\n",
    "def get_dominants_plot(features):\n",
    "    rect = np.zeros((50, 300, 3), dtype=np.uint8)\n",
    "    start = 0\n",
    "    \n",
    "    for i in range(4):\n",
    "        color = np.array(features[i*4:i*4+3])\n",
    "        percent = features[i*4+3]\n",
    "        \n",
    "        end = start + (percent * 300)\n",
    "        cv2.rectangle(rect, (int(start), 0), (int(end), 50), color.astype(\"uint8\").tolist(), -1)\n",
    "        start = end\n",
    "        \n",
    "    return rect\n",
    "\n",
    "def get_avg_plot(img):\n",
    "    average = img.mean(axis=0).mean(axis=0)\n",
    "    avg_patch = np.ones(shape=img.shape, dtype=np.uint8)*np.uint8(average)\n",
    "    return avg_patch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O9B-fSOHfZUW"
   },
   "source": [
    "#### 1. Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 63637,
     "status": "ok",
     "timestamp": 1604698353905,
     "user": {
      "displayName": "Sarah Hernández Serrano",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhPu56UtRlNcYlVlUouF6yEgbR8E4j0MVtAhTnKayY=s64",
      "userId": "18255259528200381895"
     },
     "user_tz": 360
    },
    "id": "aVnNJ0SFfZUX",
    "outputId": "c5790434-5458-41c1-f37a-bd8eeccb5366"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".DS_Store removed\n",
      ".DS_Store removed\n",
      "Classes: ['Diorite' 'Gabbro' 'Granite' 'Granodiorite']\n",
      "Counts: [78 65 70 70]\n",
      "Indices: [140 218  70   0]\n",
      "Classes dictionary: {'Diorite': 0, 'Gabbro': 1, 'Granite': 2, 'Granodiorite': 3}\n"
     ]
    }
   ],
   "source": [
    "x, y, files = load_images_from_directory(IMG_PATH, IMG_SIZE)\n",
    "\n",
    "classes, indices, counts = np.unique(y, return_counts=True, return_index=True)\n",
    "\n",
    "classes_dict = dict(zip(classes, range(0,len(classes))))\n",
    "\n",
    "print('Classes:', classes)\n",
    "print('Counts:', counts)\n",
    "print('Indices:', indices)\n",
    "print('Classes dictionary:', classes_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "5wjWTVqEfZUh",
    "outputId": "d1b8a15d-64ba-43a2-d238-aee0806d4c05"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x shape: (283, 512, 512, 3) y shape: (283,)\n"
     ]
    }
   ],
   "source": [
    "img_shape = (IMG_SIZE[0], IMG_SIZE[1], 3)\n",
    "for img, name in zip(x, files):\n",
    "    sh = np.shape(img)\n",
    "    if(sh != img_shape):\n",
    "        print('different shape', sh, name)\n",
    "print('x shape:', np.shape(x), 'y shape:', np.shape(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U1oI8d_2fZUp"
   },
   "source": [
    "#### 2. Extract colors from data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RwySlh8CfZUr"
   },
   "outputs": [],
   "source": [
    "xextracted = []\n",
    "for img in x:\n",
    "    reshape = img.reshape((img.shape[0] * img.shape[1], img.shape[2]))\n",
    "    cluster = KMeans(n_clusters=CLUSTERS).fit(reshape)\n",
    "    features = get_dominant_colors(cluster, cluster.cluster_centers_)\n",
    "    xextracted.append(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HpAHexMDfZU4",
    "outputId": "b5502e31-ff83-4fe1-e305-a186bb21aba3"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "images = []\n",
    "tittles = []\n",
    "\n",
    "for idx in indices:\n",
    "    for i in range(0+1, images_per_type_to_plot+1):\n",
    "        images.append(x[idx+i+1])\n",
    "        images.append(get_dominants_plot(xextracted[idx+i+1]))\n",
    "        images.append(get_avg_plot(x[idx+i+1]))\n",
    "        tittles.append('Original ' + y[idx+i+1])\n",
    "        tittles.append('Dominants colors ' + y[idx+i+1])\n",
    "        tittles.append('Average color ' + y[idx+i+1])\n",
    "        print(files[idx+i+1])\n",
    "    \n",
    "rows = len(indices)*images_per_type_to_plot\n",
    "columns = int(len(images) / rows)\n",
    "\n",
    "print('Color extraction')\n",
    "fig, plots = plt.subplots(rows, columns, figsize=(15,18*images_per_type_to_plot))\n",
    "for row in plots:\n",
    "    for ax in row:\n",
    "        ax.imshow(images.pop(0))\n",
    "        ax.set_title(tittles.pop(0))\n",
    "        ax.axis('off')\n",
    "plt.show(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2g6eGrGPfZU_"
   },
   "source": [
    "#### 3. Convert extracted data to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NKpbzvQ5fZVB",
    "outputId": "b5b1e8e9-5481-49c5-c4de-10f0336f2225"
   },
   "outputs": [],
   "source": [
    "yencoded = [classes_dict[c] for c in y]\n",
    "print(yencoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DM1e-f0WfZVJ",
    "outputId": "b826e7d8-c3ea-46fe-ca80-6d5db2ebd761"
   },
   "outputs": [],
   "source": [
    "# Import label encoder \n",
    "from sklearn import preprocessing \n",
    "  \n",
    "# label_encoder object knows how to understand word labels. \n",
    "label_encoder = preprocessing.LabelEncoder()\n",
    "yencoded2 = label_encoder.fit_transform(y)\n",
    "print(yencoded2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9LcRIEYHfZVN"
   },
   "outputs": [],
   "source": [
    "#np.savetxt(CSV_DIR, np.column_stack((xextracted, yencoded)), delimiter=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q-YGsp29fZVd"
   },
   "source": [
    "#### 4. Save images cropped to IMG_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LByiHwXmfZVe"
   },
   "outputs": [],
   "source": [
    "#name = 0\n",
    "#for img in x:\n",
    "#    Image.fromarray(img).save(DIR+'/'+str(name)+\".png\")\n",
    "#    name+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cYwz6b_0fZVm"
   },
   "source": [
    "#### Number of clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ifhu_dUOfZVm",
    "outputId": "60530e32-ed7c-46ee-a5c5-514def826f20"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "img = x[0]\n",
    "reshape = img.reshape((img.shape[0] * img.shape[1], img.shape[2]))\n",
    "\n",
    "Nclusters = range(2, 20)\n",
    "kmeans = [KMeans(n_clusters=i) for i in Nclusters]\n",
    "\n",
    "score = []\n",
    "distortions = []\n",
    "\n",
    "for k in kmeans:\n",
    "    cluster_labels = k.fit_predict(reshape)#k.fit(reshape)\n",
    "    distortions.appens(k.inertia_)\n",
    "    score.append(k.score(reshape))\n",
    "    \n",
    "    # The silhouette_score gives the average value for all the samples.\n",
    "    silhouette_avg = silhouette_score(reshape, cluster_labels) \n",
    "  \n",
    "    print(\"For no of clusters =\", n_clusters, \" The average silhouette_score is :\", silhouette_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6pws4tjDfZVr",
    "outputId": "f7c56895-fed7-43a0-e67d-999562036b2c"
   },
   "outputs": [],
   "source": [
    "plt.plot(Nclusters,score)\n",
    "plt.xlabel('Number of Clusters')\n",
    "plt.ylabel('Score')\n",
    "plt.title('Elbow Curve')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5yNfCEjIfZVv"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,8))\n",
    "plt.plot(Nclusters, distortions, 'bx-')\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('Distortion')\n",
    "plt.title('The Elbow Method showing the optimal k')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7qh280mwfZV_"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Colors CSV.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "PI",
   "language": "python",
   "name": "pi"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
