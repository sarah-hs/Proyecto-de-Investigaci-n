{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainFile = \"./Resources/rocks_color.csv\"\n",
    "\n",
    "DIR = \"/Users/sarah/Google Drive/Sem VII/RP Investigaci√≥n/Rock Classifier 4 copy\"\n",
    "IMAGE_SIZE = (512, 512)\n",
    "\n",
    "CLUSTERS = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rock types: [0. 1. 2. 3.]\n",
      "(81, 16) (81,)\n"
     ]
    }
   ],
   "source": [
    "# 1. LOAD DATA\n",
    "import numpy as np\n",
    "data = np.loadtxt(trainFile, delimiter=\",\")\n",
    "\n",
    "#data = data[data[:,-1] != 0]\n",
    "#data = data[data[:,-1] != 1]\n",
    "#data = data[data[:,-1] != 2]\n",
    "#data = data[data[:,-1] != 3]\n",
    "\n",
    "classes = np.unique(data[:,-1])\n",
    "print('Rock types:', classes)\n",
    "\n",
    "x = data[:, :-1]\n",
    "y = data[:, -1]\n",
    "print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. SPLIT DATA\n",
    "from sklearn.model_selection import train_test_split as splitter\n",
    "xtrain, xtest,ytrain,ytest = splitter(x,y,train_size=0.7,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. NORMALIZE DATA\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "normalizer = MinMaxScaler()\n",
    "xtrainNorm = normalizer.fit_transform(xtrain)\n",
    "xtestNorm = normalizer.fit_transform(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4. TRAINING MODEL\n",
    "#   Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "logReg = LogisticRegression(solver='lbfgs')\n",
    "logReg.fit(xtrainNorm, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#   KNN\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "knn.fit(xtrainNorm, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "<<MODELS REPORT LLOG. REGRESSION>>\n",
      "Logistic Regression: 0.4\n",
      "Logistic Regression Model accuracy: 0.4\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.38      0.30      0.33        10\n",
      "         1.0       0.38      1.00      0.55         3\n",
      "         2.0       0.00      0.00      0.00         8\n",
      "         3.0       0.44      1.00      0.62         4\n",
      "\n",
      "    accuracy                           0.40        25\n",
      "   macro avg       0.30      0.57      0.37        25\n",
      "weighted avg       0.27      0.40      0.30        25\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sarah/opt/miniconda3/envs/tf2/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# 5. TESTING MODEL\n",
    "from sklearn import metrics\n",
    "\n",
    "# Logistic Regression\n",
    "print(\"\\n<<MODELS REPORT LLOG. REGRESSION>>\")\n",
    "print(\"Logistic Regression:\",logReg.score(xtestNorm, ytest))\n",
    "\n",
    "predictions = logReg.predict(xtestNorm)\n",
    "print(\"Logistic Regression Model accuracy:\", metrics.accuracy_score(ytest, predictions))\n",
    "print(metrics.classification_report(ytest,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "<<MODEL REPORT KNN>>\n",
      "KNN: 0.8\n",
      "KNN Model accuracy: 0.8\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.82      0.90      0.86        10\n",
      "         1.0       0.67      0.67      0.67         3\n",
      "         2.0       1.00      0.62      0.77         8\n",
      "         3.0       0.67      1.00      0.80         4\n",
      "\n",
      "    accuracy                           0.80        25\n",
      "   macro avg       0.79      0.80      0.77        25\n",
      "weighted avg       0.83      0.80      0.80        25\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# KNN\n",
    "print(\"\\n<<MODEL REPORT KNN>>\")\n",
    "print(\"KNN:\",knn.score(xtestNorm, ytest))\n",
    "\n",
    "predictions = knn.predict(xtestNorm)\n",
    "print(\"KNN Model accuracy:\", metrics.accuracy_score(ytest, predictions))\n",
    "print(metrics.classification_report(ytest,predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "import tensorflow as tf\n",
    "import cv2, os\n",
    "from PIL import Image, ImageOps\n",
    "import numpy as np\n",
    "from itertools import repeat\n",
    "\n",
    "def load_images_from_folder(folder, size):\n",
    "    images = []\n",
    "    for filename in os.listdir(folder):\n",
    "        if(not filename.lower().endswith(('.png', '.jpg', '.jpeg', '.tiff', '.bmp', '.gif'))):\n",
    "            print(filename, 'file removed')\n",
    "            continue\n",
    "        img = Image.open(os.path.join(folder,filename))\n",
    "        fit_and_resized_image = ImageOps.fit(img, size, Image.ANTIALIAS)\n",
    "        img = np.array(fit_and_resized_image)\n",
    "        img = img[...,:3]\n",
    "        if img is not None:\n",
    "            images.append(img)\n",
    "    return images\n",
    "\n",
    "def load_images_from_directory(path, size):\n",
    "    paths = os.listdir(path)\n",
    "    x = []; y = []; lbl_dict = {}; lbl_num = 0; counts = []\n",
    "    for folder in paths:\n",
    "        if(os.path.isfile(folder)):#  or folder == 'granodiorite'\n",
    "            print(folder, 'file removed')\n",
    "            continue\n",
    "        images = load_images_from_folder(os.path.join(path, folder), size)\n",
    "        lbl_nums = list(repeat(lbl_num, len(images)))\n",
    "        x.extend(images)\n",
    "        y.extend(lbl_nums)\n",
    "        counts.append(len(lbl_nums))\n",
    "        lbl_dict[lbl_num] = folder\n",
    "        lbl_num += 1\n",
    "    return (x, y, lbl_dict, counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".DS_Store file removed\n",
      ".DS_Store file removed\n",
      ".DS_Store file removed\n",
      ".DS_Store file removed\n",
      ".DS_Store file removed\n",
      "['granodiorite', 'granite', 'diorite', 'gabbro'] [3, 3, 3, 3]\n",
      "Samples shape: (12, 512, 512, 3)\n"
     ]
    }
   ],
   "source": [
    "x_pred, y_pred, labels, counts = load_images_from_directory(DIR, IMAGE_SIZE)\n",
    "\n",
    "print(list(labels.values()), counts)\n",
    "print('Samples shape:', np.shape(x_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dominant_colors(cluster, centroids):\n",
    "    # Get the number of different clusters, create histogram, and normalize\n",
    "    lbls = np.arange(0, len(np.unique(cluster.labels_)) + 1)\n",
    "    (hist, _) = np.histogram(cluster.labels_, bins = lbls)\n",
    "    hist = hist.astype(\"float\"); hist /= hist.sum()\n",
    "\n",
    "    # Color and frecuency list by the iteration through each cluster\n",
    "    features = []\n",
    "    colors = sorted([(percent, color) for (percent, color) in zip(hist, centroids)])\n",
    "    \n",
    "    for (percent, color) in colors:\n",
    "        features.extend(color)\n",
    "        features.append(percent)\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[106.01729909061288, 102.64074765247786, 94.47999052104623, 0.1292266845703125, 143.7068311195446, 140.20458162453326, 134.65337883332313, 0.24884033203125, 201.65234386064296, 199.23710522588868, 197.20875230137375, 0.2700042724609375, 173.9617211420905, 170.9813690804635, 167.55651487119565, 0.3519287109375]\n",
      "(12, 16)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "extracted_colors = []\n",
    "for img in x_pred:\n",
    "    reshape = img.reshape((img.shape[0] * img.shape[1], 3))\n",
    "    cluster = KMeans(n_clusters=CLUSTERS).fit(reshape)\n",
    "    features = get_dominant_colors(cluster, cluster.cluster_centers_)\n",
    "    extracted_colors.append(features)\n",
    "\n",
    "print(extracted_colors[0])\n",
    "print(np.shape(extracted_colors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "name = 61\n",
    "#for img in x_pred:\n",
    " #   Image.fromarray(img).save(str(name)+\".png\")\n",
    "  #  name+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'granodiorite', 1: 'granite', 2: 'diorite', 3: 'gabbro'}\n"
     ]
    }
   ],
   "source": [
    "classes = {0: 'granodiorite', 1: 'granite', 2: 'diorite', 3: 'gabbro'}\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. NORMALIZE DATA\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "tt = MinMaxScaler()\n",
    "color_norm = tt.fit_transform(extracted_colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "granodiorite\n",
      "granodiorite\n"
     ]
    }
   ],
   "source": [
    "print(labels[y_pred[0]])\n",
    "print(classes[int(knn.predict([extracted_colors[0]])[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25\n"
     ]
    }
   ],
   "source": [
    "print(knn.score(extracted_colors, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_data = logReg.predict_proba(extracted_colors)\n",
    "\n",
    "real = []\n",
    "predicted = []\n",
    "precision = []\n",
    "\n",
    "for i in range(0, len(output_data)):\n",
    "    real.append(labels[y_pred[i]])\n",
    "    predicted.append(classes[int(knn.predict([extracted_colors[i]]))])\n",
    "    precision.append(max(output_data[i]))\n",
    "#    print(classes[y_pred[i]], classes[np.argmax(output_data[i])], max(output_data[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Real class</th>\n",
       "      <th>Predicted class</th>\n",
       "      <th>Precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>granodiorite</td>\n",
       "      <td>granodiorite</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>granodiorite</td>\n",
       "      <td>granodiorite</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>granodiorite</td>\n",
       "      <td>granodiorite</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>granite</td>\n",
       "      <td>granodiorite</td>\n",
       "      <td>0.989216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>granite</td>\n",
       "      <td>granodiorite</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>granite</td>\n",
       "      <td>granodiorite</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>diorite</td>\n",
       "      <td>granodiorite</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>diorite</td>\n",
       "      <td>granodiorite</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>diorite</td>\n",
       "      <td>granodiorite</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>gabbro</td>\n",
       "      <td>granodiorite</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>gabbro</td>\n",
       "      <td>granodiorite</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>gabbro</td>\n",
       "      <td>granodiorite</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Real class Predicted class  Precision\n",
       "0   granodiorite    granodiorite   1.000000\n",
       "1   granodiorite    granodiorite   1.000000\n",
       "2   granodiorite    granodiorite   1.000000\n",
       "3        granite    granodiorite   0.989216\n",
       "4        granite    granodiorite   1.000000\n",
       "5        granite    granodiorite   1.000000\n",
       "6        diorite    granodiorite   1.000000\n",
       "7        diorite    granodiorite   1.000000\n",
       "8        diorite    granodiorite   1.000000\n",
       "9         gabbro    granodiorite   1.000000\n",
       "10        gabbro    granodiorite   1.000000\n",
       "11        gabbro    granodiorite   1.000000"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# get the list of tuples from two lists.  \n",
    "# and merge them by using zip().  \n",
    "list_of_tuples = list(zip(real, predicted, precision))  \n",
    "  \n",
    "# Converting lists of tuples into  \n",
    "# pandas Dataframe.  \n",
    "df = pd.DataFrame(list_of_tuples, columns = ['Real class', 'Predicted class', 'Precision']) \n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<< Well predicted >>\n",
      "granite 0 / 20\n",
      "diorite 0 / 20\n",
      "gabbro 0 / 20\n"
     ]
    }
   ],
   "source": [
    "granite = 0\n",
    "diorite = 0\n",
    "gabbro = 0\n",
    "\n",
    "print('<< Well predicted >>')\n",
    "\n",
    "for i in range(len(real)):\n",
    "    if(real[i] == predicted[i]):\n",
    "        if(real[i] == 'granite'):\n",
    "            granite+=1\n",
    "        elif(real[i] == 'diorite'):\n",
    "            diorite+=1\n",
    "        elif(real[i] == 'gabbro'):\n",
    "            gabbro+=1\n",
    "print('granite', granite, '/ 20')\n",
    "print('diorite', diorite, '/ 20')\n",
    "print('gabbro', gabbro, '/ 20')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2",
   "language": "python",
   "name": "tf2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
