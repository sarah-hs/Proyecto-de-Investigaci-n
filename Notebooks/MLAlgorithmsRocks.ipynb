{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rock types: [0. 1. 2. 3.]\n",
      "(81, 12) (81,)\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Sarah Hernández Serrano\n",
    "    2nd TEST\n",
    "Rock CLASSIFIER\n",
    "\"\"\"\n",
    "\n",
    "# 1. LOAD DATA\n",
    "trainFile = \"./Resources/rocks_color.csv\"\n",
    "\n",
    "import numpy as np\n",
    "data = np.loadtxt(trainFile, delimiter=\",\")\n",
    "\n",
    "#data = data[data[:,-1] != 0]\n",
    "#data = data[data[:,-1] != 1]\n",
    "#data = data[data[:,-1] != 2]\n",
    "#data = data[data[:,-1] != 3]\n",
    "\n",
    "classes = np.unique(data[:,-1])\n",
    "print('Rock types:', classes)\n",
    "\n",
    "x = data[:, :-1]\n",
    "y = data[:, -1]\n",
    "print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. SPLIT DATA\n",
    "from sklearn.model_selection import train_test_split as splitter\n",
    "xtrain, xtest,ytrain,ytest = splitter(x,y,train_size=0.8,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. NORMALIZE DATA\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "normalizer = MinMaxScaler()\n",
    "xtrainNorm = normalizer.fit_transform(xtrain)\n",
    "xtestNorm = normalizer.fit_transform(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "<<MODELS REPORT>>\n",
      "KNN: 0.4117647058823529\n",
      "0.29411764705882354\n",
      "KNN Model accuracy: 0.4117647058823529\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.45      0.83      0.59         6\n",
      "         1.0       0.00      0.00      0.00         2\n",
      "         2.0       0.00      0.00      0.00         7\n",
      "         3.0       0.50      1.00      0.67         2\n",
      "\n",
      "    accuracy                           0.41        17\n",
      "   macro avg       0.24      0.46      0.31        17\n",
      "weighted avg       0.22      0.41      0.29        17\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sarah/opt/miniconda3/envs/tf2/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# 4. TRAINING MODELS AND TESTING MODELS\n",
    "from sklearn import metrics\n",
    "print(\"\\n<<MODELS REPORT>>\")\n",
    "\n",
    "#   KNN\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "knn.fit(xtrainNorm, ytrain)\n",
    "print(\"KNN:\",knn.score(xtestNorm, ytest))\n",
    "# Test model\n",
    "\n",
    "predictions = knn.predict(xtestNorm)\n",
    "print(knn.score(xtest, ytest))\n",
    "print(\"KNN Model accuracy:\", metrics.accuracy_score(ytest, predictions))\n",
    "print(metrics.classification_report(ytest,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision trees: 0.5294117647058824\n",
      "0.4117647058823529\n",
      "Decision trees Model accuracy: 0.5294117647058824\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.43      0.50      0.46         6\n",
      "         1.0       0.25      0.50      0.33         2\n",
      "         2.0       0.75      0.43      0.55         7\n",
      "         3.0       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.53        17\n",
      "   macro avg       0.61      0.61      0.59        17\n",
      "weighted avg       0.61      0.53      0.54        17\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#   Decision Trees\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "decisionTree = DecisionTreeClassifier(class_weight='balanced',random_state=0)\n",
    "decisionTree.fit(xtrainNorm, ytrain)\n",
    "print(\"Decision trees:\",decisionTree.score(xtestNorm, ytest))\n",
    "\n",
    "predictions = decisionTree.predict(xtestNorm)\n",
    "print(decisionTree.score(xtest, ytest))\n",
    "print(\"Decision trees Model accuracy:\", metrics.accuracy_score(ytest, predictions))\n",
    "print(metrics.classification_report(ytest,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression: 0.23529411764705882\n",
      "0.29411764705882354\n",
      "Logistic Regression Model accuracy: 0.23529411764705882\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.25      0.17      0.20         6\n",
      "         1.0       0.12      0.50      0.20         2\n",
      "         2.0       0.00      0.00      0.00         7\n",
      "         3.0       0.40      1.00      0.57         2\n",
      "\n",
      "    accuracy                           0.24        17\n",
      "   macro avg       0.19      0.42      0.24        17\n",
      "weighted avg       0.15      0.24      0.16        17\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sarah/opt/miniconda3/envs/tf2/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#   Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "logReg = LogisticRegression(solver='lbfgs')\n",
    "logReg.fit(xtrainNorm, ytrain)\n",
    "print(\"Logistic Regression:\",logReg.score(xtestNorm, ytest))\n",
    "\n",
    "predictions = logReg.predict(xtestNorm)\n",
    "print(logReg.score(xtest, ytest))\n",
    "print(\"Logistic Regression Model accuracy:\", metrics.accuracy_score(ytest, predictions))\n",
    "print(metrics.classification_report(ytest,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Support Vector Machines: 0.4117647058823529\n",
      "0.35294117647058826\n",
      "SVM Model accuracy: 0.4117647058823529\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.42      0.83      0.56         6\n",
      "         1.0       0.00      0.00      0.00         2\n",
      "         2.0       0.00      0.00      0.00         7\n",
      "         3.0       0.40      1.00      0.57         2\n",
      "\n",
      "    accuracy                           0.41        17\n",
      "   macro avg       0.20      0.46      0.28        17\n",
      "weighted avg       0.19      0.41      0.26        17\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sarah/opt/miniconda3/envs/tf2/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#   Support Vector Machines\n",
    "from sklearn.svm import SVC\n",
    "svmc = SVC(gamma='auto')\n",
    "svmc.fit(xtrainNorm, ytrain)\n",
    "print(\"Support Vector Machines:\",svmc.score(xtestNorm, ytest))\n",
    "\n",
    "predictions = svmc.predict(xtestNorm)\n",
    "print(svmc.score(xtest, ytest))\n",
    "print(\"SVM Model accuracy:\", metrics.accuracy_score(ytest, predictions))\n",
    "print(metrics.classification_report(ytest,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'livelossplot'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-2b18abca9c71>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mto_categorical\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0moptimizers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mlivelossplot\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPlotLossesKeras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'livelossplot'"
     ]
    }
   ],
   "source": [
    "# cnn model\n",
    "import tensorflow as tf\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from numpy import dstack\n",
    "from pandas import read_csv\n",
    "from matplotlib import pyplot\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Conv1D, Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling1D, MaxPooling2D\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras import optimizers\n",
    "from livelossplot import PlotLossesKeras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit and evaluate a model\n",
    "\n",
    "trainX = xtrainNorm.reshape((xtrainNorm.shape[0], 4, 4))\n",
    "testX = xtestNorm.reshape((xtestNorm.shape[0], 4, 4))\n",
    "\n",
    "# zero-offset class values\n",
    "trainy = ytrain\n",
    "testy = ytest\n",
    "# one hot encode y\n",
    "trainy = to_categorical(trainy)\n",
    "testy = to_categorical(testy)\n",
    "print(trainX.shape, trainy.shape, testX.shape, testy.shape)\n",
    "\n",
    "verbose, epochs, batch_size = 0, 10, 32\n",
    "n_timesteps, n_features, n_outputs = trainX.shape[1], trainX.shape[2], len(classes)\n",
    "print(n_timesteps, n_features)\n",
    "# scale data\n",
    "#trainX, testX = scale_data(trainX, testX, param)\n",
    "model = Sequential()\n",
    "model.add(Conv1D(filters=32, kernel_size=2, activation='relu', input_shape=(n_timesteps,n_features)))\n",
    "model.add(Conv1D(filters=32, kernel_size=2, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(n_outputs, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# fit network\n",
    "model.fit(trainX, trainy, epochs=epochs, batch_size=batch_size, verbose=verbose)\n",
    "# evaluate model\n",
    "loss, acc = model.evaluate(testX, testy, verbose=0)\n",
    "print('Accuracy: %.3f' % acc)\n",
    "print('Loss: %.3f' % loss)\n",
    "predictions = model.predict_classes(testX)\n",
    "\n",
    "print(\"CNN Model accuracy:\", metrics.accuracy_score(ytest, predictions))\n",
    "print(metrics.classification_report(ytest,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3,3), padding=\"same\", input_shape = (n_timesteps,n_features, 1), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Conv2D(64, (2,2), padding=\"same\", activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(n_outputs, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0), metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tr = trainX.reshape((trainX.shape[0], trainX.shape[1], trainX.shape[2], 1))\n",
    "x_tst = testX.reshape((testX.shape[0], testX.shape[1], testX.shape[2], 1))\n",
    "\n",
    "y_tr = trainy\n",
    "y_tst = testy\n",
    "\n",
    "# Compilar el modelo usando las métricas de accuracy para medir el rendimiento\n",
    "#model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# 4. ENTRENAR EL MODELO\n",
    "model.fit(x_tr, y_tr, epochs=10, batch_size=32, validation_data=(x_tst, y_tst), verbose=0)\n",
    "\n",
    "\n",
    "# 5. EVALUAR EL MODELO\n",
    "loss, acc = model.evaluate(x_tst, y_tst, verbose=0)\n",
    "print('Accuracy: %.3f' % acc)\n",
    "print('Loss: %.3f' % loss)\n",
    "predictions = model.predict_classes(x_tst)\n",
    "\n",
    "print(\"DNN Model accuracy:\", metrics.accuracy_score(ytest, predictions))\n",
    "print(metrics.classification_report(ytest,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2",
   "language": "python",
   "name": "tf2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
