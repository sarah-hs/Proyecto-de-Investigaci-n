#LyX 2.3 created this file. For more info see http://www.lyx.org/
\lyxformat 544
\begin_document
\begin_header
\save_transient_properties true
\origin unavailable
\textclass IEEEtran
\begin_preamble
% for subfigures/subtables
\usepackage{titlesec}
\titlespacing{\subsubsection}{0pt}{0.6em}{0pt}
\usepackage[caption=false,font=footnotesize]{subfig}
\usepackage{diagbox}
\usepackage{array}
\usepackage{listings}
\lstdefinelanguage{Swift}{language=bash,morekeywords={fix},}
\usepackage{color}
\definecolor{lightgray}{RGB}{246,246,246}
\definecolor{darkgray}{RGB}{128,128,128}
\end_preamble
\options journal
\use_default_options false
\begin_modules
graphicboxes
\end_modules
\maintain_unincluded_children false
\language english
\language_package default
\inputencoding ascii
\fontencoding global
\font_roman "default" "default"
\font_sans "default" "default"
\font_typewriter "default" "default"
\font_math "auto" "auto"
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100 100
\font_tt_scale 100 100
\use_microtype false
\use_dash_ligatures true
\graphics default
\default_output_format default
\output_sync 1
\bibtex_command bibtex
\index_command default
\float_placement H
\paperfontsize default
\spacing single
\use_hyperref true
\pdf_title "Your Title"
\pdf_author "Your Name"
\pdf_bookmarks true
\pdf_bookmarksnumbered true
\pdf_bookmarksopen true
\pdf_bookmarksopenlevel 1
\pdf_breaklinks false
\pdf_pdfborder true
\pdf_colorlinks false
\pdf_backref false
\pdf_pdfusetitle false
\pdf_quoted_options "pdfpagelayout=OneColumn, pdfnewwindow=true, pdfstartview=XYZ, plainpages=false"
\papersize default
\use_geometry false
\use_package amsmath 1
\use_package amssymb 1
\use_package cancel 0
\use_package esint 0
\use_package mathdots 1
\use_package mathtools 0
\use_package mhchem 1
\use_package stackrel 0
\use_package stmaryrd 0
\use_package undertilde 0
\cite_engine biblatex-natbib
\cite_engine_type numerical
\biblio_style jurabib
\biblatex_bibstyle ieee
\biblatex_citestyle numeric
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\justification true
\use_refstyle 0
\use_minted 0
\index Index
\shortcut idx
\color #008000
\end_index
\secnumdepth 3
\tocdepth 3
\paragraph_separation indent
\paragraph_indentation default
\is_math_indent 0
\math_numbering_side default
\quotes_style english
\dynamic_quotes 0
\papercolumns 2
\papersides 1
\paperpagestyle default
\listings_params "breaklines=true,captionpos=b,aboveskip=3mm,belowskip=3mm,showstringspaces=false,columns=flexible,basicstyle={\scriptsize\ttfamily},breakatwhitespace=true,numbers=left,numberstyle={\scriptsize\ttfamily},xleftmargin={0.7cm},framexleftmargin={0.7em},numbersep=8pt,tabsize=3,backgroundcolor={\color{lightgray}},commentstyle={\color{darkgray}}"
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Standard
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
begin{titlepage}
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\align left
\begin_inset Float figure
wide false
sideways false
status collapsed

\begin_layout Plain Layout
\align left
\begin_inset Graphics
	filename Images/Logo_UM.png
	lyxscale 7
	width 2.5cm
	height 2.5cm
	keepAspectRatio

\end_inset


\begin_inset space \hspace{}
\length 12cm
\end_inset


\begin_inset Graphics
	filename Images/Logo_FIT.png
	lyxscale 75
	width 2.5cm
	height 2.5cm
	keepAspectRatio

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
\align center

\series bold
\size huge
Universidad de Montemorelos
\end_layout

\begin_layout Standard

\series bold
\size larger
\begin_inset VSpace 1cm
\end_inset


\end_layout

\begin_layout Standard
\align center

\series bold
\size larger
Facultad de Ingeniería y Tecnología
\end_layout

\begin_layout Standard
\align center

\series bold
\size larger
Ingeniería en Sistemas Computacionales
\end_layout

\begin_layout Standard

\series bold
\size larger
\begin_inset VSpace 1.6cm
\end_inset


\end_layout

\begin_layout Standard
\align center

\series bold
\size huge
Automatic classification of plutonic rocks with machine learning applied
 to extracted colors on iOS devices
\end_layout

\begin_layout Standard

\series bold
\size larger
\begin_inset VSpace 1.6cm
\end_inset


\end_layout

\begin_layout Standard
\align center

\series bold
\size larger
Sarah Hernández Serrano
\end_layout

\begin_layout Standard
\align center

\series bold
\size larger
1170469
\end_layout

\begin_layout Standard

\series bold
\size larger
\begin_inset VSpace 1.6cm
\end_inset


\end_layout

\begin_layout Standard
\align center

\series bold
\size larger
Asesor: Dr.
 Germán Harvey Alférez Salinas
\end_layout

\begin_layout Standard

\series bold
\size larger
\begin_inset VSpace 1.6cm
\end_inset


\end_layout

\begin_layout Standard
\align center

\series bold
\size larger
Montemorelos, Nuevo León, México
\end_layout

\begin_layout Standard
\align center

\series bold
\size larger
00 de mayo de 2021
\end_layout

\begin_layout Standard
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
end{titlepage}
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Newpage pagebreak
\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
begin{titlepage}
\end_layout

\end_inset


\end_layout

\begin_layout Standard

\series bold
\size larger
\begin_inset VSpace 7cm
\end_inset


\end_layout

\begin_layout Abstract
The classification of different rocks can provide us with important information
 about the conditions under they formed and the tectonic environment.
 Color is a key property for rock classification, however, it is difficult
 to describe because perceived colors in rocks also depend on the observer's
 experience with similar observations; so a color may often be named differently
 by different persons.
 Moreover, the equipment for rock classification is expensive, which makes
 this equipment prohibitive to geology students and amateurs.
 The contribution of this research work is twofold.
 First, we present an iOS application that uses machine learning to classify
 images of the following plutonic rocks: granite, granodiorite, gabbro,
 and diorite.
 In order to use the best suited machine learning algorithm in the application,
 the effectiveness of the Logistic Regression, K-Nearest Neighbors, Decision
 Trees, Support Vector Machine, and Convolutional Neural Network algorithms
 is compared.
 Second, since color is a key property for rock classification, feature
 reduction was applied in rock images extracting just the four dominant
 colors before training the machine learning algorithms.
 To this end, the k-means clustering method was used.
 The best results were achieved with K-Nearest Neighbors algorithm.
 The evaluation results of the algorithm are the following: 82% of accuracy,
 84% of precision, 89% of recall, and 83% of F1-score.
\end_layout

\begin_layout Keywords
Machine Learning, Color Extraction, iOS Devices, Geology, Rock Classification,
 Features Reduction, Dominant Colors, K-means Clustering, Logistic Regression,
 K-Nearest Neighbors, Support Vector Machine, Convolutional Neural Network,
 Decision Trees.
\end_layout

\begin_layout Standard
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
end{titlepage}
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Newpage pagebreak
\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
begin{titlepage}
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset CommandInset toc
LatexCommand tableofcontents

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
end{titlepage}
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Newpage pagebreak
\end_inset


\end_layout

\begin_layout Title
Automatic classification of plutonic rocks with machine learning applied
 to extracted colors on iOS devices
\end_layout

\begin_layout Author
Sarah
\begin_inset space ~
\end_inset

Hernández
\begin_inset space ~
\end_inset

and
\begin_inset space ~
\end_inset

Germán
\begin_inset space ~
\end_inset

H.
\begin_inset space ~
\end_inset

Alférez
\begin_inset Foot
status open

\begin_layout Plain Layout
Sarah
\begin_inset space ~
\end_inset

Hernández is a computer science engineering student at the School of Engineering
 and Technology of Montemorelos University, Nuevo León, Mexico, e-mail:
 
\begin_inset CommandInset href
LatexCommand href
target "1170469@alumno.um.edu.mx"
type "mailto:"
literal "false"

\end_inset

.
\end_layout

\end_inset


\begin_inset Foot
status open

\begin_layout Plain Layout
Germán H.
 Alferez, Ph.D., is the director of the Institute of Data Science and professor
 at the School of Engineering and Technology of Montemorelos University,
 Nuevo León, Mexico, e-mail: 
\begin_inset CommandInset href
LatexCommand href
target "harveyalferez@um.edu.mx"
type "mailto:"
literal "false"

\end_inset

.
\end_layout

\end_inset


\end_layout

\begin_layout Special Paper Notice
School of Engineering and Technology, Montemorelos University, Mexico
\end_layout

\begin_layout Section
Introduction
\end_layout

\begin_layout Subsection
Background
\end_layout

\begin_layout Standard
\begin_inset Flex Paragraph Start
status open

\begin_layout Plain Layout
\begin_inset Argument 1
status open

\begin_layout Plain Layout
T
\end_layout

\end_inset


\end_layout

\end_inset

he classification of different rocks can provide us with important information
 about the conditions under which they formed.
 They can also tell us much about the tectonic environment, given that they
 are closely linked to the convection of tectonic plates.
 Their mineral and chemical makeup can be used to learn about the composition,
 temperature and pressure that exists within the Earth’s mantle 
\begin_inset CommandInset citation
LatexCommand citep
key "Williams-2015"
literal "false"

\end_inset

.
\end_layout

\begin_layout Standard
Plutonic rocks are a type of igneous rock (one of the three main types of
 rocks in the world and also the most common) formed when magma in the middle
 of the volcano cools and solidifies below the Earth’s surface.
 They come in many different sizes and colors, this is a characteristic
 of plutonic rocks, and have a wide variety of uses, an important use is
 as stone for buildings and statues 
\begin_inset CommandInset citation
LatexCommand citep
key "NGS-2019,Study-2013"
literal "false"

\end_inset

.
\end_layout

\begin_layout Standard
This project works by extracting the main dominant colors from plutonic
 rock images to classify them.
 Rock color is an attribute of visual perception that can be described by
 color names.
 Color changes in rocks may indicate changes in the rock’s mineral assemblage,
 texture, organic carbon content (shales), or other properties 
\begin_inset CommandInset citation
LatexCommand citep
key "NRCS-2012"
literal "false"

\end_inset

.
 That is why color is a key property for rock classification and was used
 in this work.
\end_layout

\begin_layout Standard
Machine learning is a branch of artificial intelligence and is becoming
 an appealing tool in various fields of earth sciences, especially in prediction
s and resources estimation 
\begin_inset CommandInset citation
LatexCommand citep
key "Cate2017"
literal "false"

\end_inset

.
 For that reason, we implemented machine learning algorithms in order to
 extract the dominant colors from rock images and also classify with them
 new rocks into four types of plutonic rocks: granite, granodiorite, gabbro
 and diorite.
\end_layout

\begin_layout Subsection
Problem Statement
\end_layout

\begin_layout Standard
The equipment for rock classification is expensive, which makes this equipment
 prohibitive to geology students and amateurs.
 In addtion, despite the fact that color is a key property for rock classificati
on, it is an attribute difficult to describe because perceived colors in
 rocks also depend on the stimulus area and the observer's experience with
 similar observations; so a color may often be named differently by different
 persons 
\begin_inset CommandInset citation
LatexCommand citep
key "NRCS-2012"
literal "false"

\end_inset

.
\end_layout

\begin_layout Subsection
Justification
\end_layout

\begin_layout Standard
There are three reasons to create an iOS mobile application that allows
 the classification of rocks through colors with machine learning.
 First, no such application exists.
 A mobile application offers the flexibility to carry out the classification
 on real time and could be an alternative to expensive traditional methods
 of rock classification.
 Second, machine learning provides easy classification of images within
 an application.
 Third and most important, the extraction of the dominant colors from rock
 images is useful to reduce the number of features in images during the
 training of machine learning algorithms and will allow geologists to more
 accurately detect color changes in rocks.
\end_layout

\begin_layout Subsection
Objectives
\end_layout

\begin_layout Standard
The main objective is to create an iOS application that uses machine learning
 to extract the dominant colors from images and use these colors to classify
 plutonic rocks.
 This objective can be achieved with the following sub-objectives:
\end_layout

\begin_layout Itemize
Determine the best k number of clusters to use in the k-means clustering
 machine learning method to extract the dominant colors from rock images.
\end_layout

\begin_layout Itemize
Use the extracted dominant colors and their percentage as input to train
 the following machine learning algorithms: Logistic regression, K-Nearest
 Neighbors, Decision Trees, Support Vector Machine, and Convolutional Neural
 Network.
\end_layout

\begin_layout Itemize
Validate the algorithms to get the best suited algorithm for the mobile
 application.
\end_layout

\begin_layout Itemize
Deploy the most suitable classification model in an iOS mobile device.
\end_layout

\begin_layout Itemize
Test the effectiveness of the application with images taken from new plutonic
 rocks.
\end_layout

\begin_layout Subsection
Hypothesis
\end_layout

\begin_layout Standard
The training of a machine learning model with just the dominant colors extracted
 from rock images can provide us an effective way for the classification
 of rocks.
\end_layout

\begin_layout Section
Theoretical Foundation
\end_layout

\begin_layout Subsection
Underpinnings of our Approach
\end_layout

\begin_layout Standard
Our approach is based on the following concepts 
\shape italic
\emph on
(see Fig.
 1
\shape default
\emph default
).
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status collapsed

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Images/Map of concepts.png
	lyxscale 20
	width 100col%

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Underpinnings of our approach
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Subsubsection
Plutonic rocks
\end_layout

\begin_layout Standard
Plutonic rocks are solidified inside the earth’s crust, usually from magma,
 although they may have been formed by a different mechanism.
 Plutonic rocks are generally coarse-grained, but not all coarse-grained
 rocks are plutonic 
\begin_inset CommandInset citation
LatexCommand citep
key "RACEFEN-gg"
literal "false"

\end_inset

.
\end_layout

\begin_layout Standard
This project analyze the following four types of plutonic rocks:
\end_layout

\begin_layout Paragraph
Granite
\end_layout

\begin_layout Standard
Granite rocks are plutonic rocks with a granular texture, composed of similar
 amounts of quartz, potassium feldspar, and plagioclase as essential minerals,
 and smaller amounts of one or more minerals, such as biotite, muscovite
 or hornblende 
\begin_inset CommandInset citation
LatexCommand citep
key "RACEFEN-gg"
literal "false"

\end_inset

.
\end_layout

\begin_layout Paragraph
Granodiorite
\end_layout

\begin_layout Standard
It is a plutonic rock of the granitoid family, characterized by quartz because
 plagioclase constitutes more than 2/3 of the total feldspars.
 Generally, together with granite, it is the most abundant rock of the great
 batholiths.
 Its volcanic equivalent is dacite 
\begin_inset CommandInset citation
LatexCommand citep
key "RACEFEN-gg"
literal "false"

\end_inset

.
 Granodiorite is similar to granite, but with less potassium feldspar and
 more plagioclase.
\end_layout

\begin_layout Paragraph
Gabbro
\end_layout

\begin_layout Standard
It is a plutonic rock composed mainly of calcium plagioclase and clinopyroxene
 or orthopiroxene, with or without olivine or amphibole.
 It is the intrusive equivalent of basalt.
 It is distinguished from diorite by the nature of plagioclase, which is
 higher in calcium than in sodium 
\begin_inset CommandInset citation
LatexCommand citep
key "RACEFEN-gg"
literal "false"

\end_inset

.
\end_layout

\begin_layout Paragraph
Diorite
\end_layout

\begin_layout Standard
Has about the same structural properties as granite but darker colour and
 more limited supply.
 Commonly is composed of about two-thirds plagioclase feldspar and one-third
 dark-coloured minerals, such as hornblende or biotite.
 The presence of sodium-rich feldspar, oligoclase or andesine, in contrast
 to calcium-rich plagioclase, labradorite or bytownite, is the main distinction
 between diorite and gabbro 
\begin_inset CommandInset citation
LatexCommand citep
key "Britannica-Diorite"
literal "false"

\end_inset

.
\end_layout

\begin_layout Subsubsection
Machine Learning
\end_layout

\begin_layout Standard
Machine learning is a branch of artificial intelligence that lies at the
 intersection of computer science, engineering, and statistics and often
 appears in other disciplines.
 Any field that needs to interpret and act on data can benefit from its
 techniques.
 Machine Learning systems can be classified according to the type of supervision
 they get during training 
\begin_inset CommandInset citation
LatexCommand citep
key "Harrington2012,Geron2019"
literal "false"

\end_inset

.
 There are two major categories:
\end_layout

\begin_layout Paragraph
Supervised learning
\end_layout

\begin_layout Standard
In supervised learning, the training set you feed to the algorithm includes
 the desired solutions, called labels.
 A typical supervised learning task is classification 
\begin_inset CommandInset citation
LatexCommand citep
key "Geron2019"
literal "false"

\end_inset

.
\end_layout

\begin_layout Standard
Below are described some common algorithms of supervised learning.
\end_layout

\begin_layout Itemize
Logistic Regression algorithm is commonly used to estimate the probability
 that an instance belongs to a particular class.
 This model computes a weighted sum of the input features (plus a bias term)
 and outputs the logistic of this result.
 The logistic is a sigmoid function that outputs a number between 0 and
 1.
 This makes it a binary classifier 
\begin_inset CommandInset citation
LatexCommand citep
key "Geron2019"
literal "false"

\end_inset

.
\end_layout

\begin_layout Itemize
K-Nearest Neighbors is an algorithm in which its priniciple is to find a
 predefined number of training samples closest in distance to the new point,
 and predict the label from these.
 Despite its simplicity, nearest neighbors has been successful in a large
 number of classification and regression problems, including handwritten
 digits and satellite image scenes.
 Being a non-parametric method, it is often successful in classification
 situations where the decision boundary is very irregular 
\begin_inset CommandInset citation
LatexCommand citep
key "sklearn-KNN"
literal "false"

\end_inset

.
\end_layout

\begin_layout Itemize
Decision Trees algorithm consists of split nodes and leaf nodes.
 Each split node performs a split decision and routes a data sample either
 to the left or the right child node.
 In the tree structures, leaves represent the labels, nonleaf nodes are
 the input features, and branches represent conjunctions of features that
 lead to the classifications 
\begin_inset CommandInset citation
LatexCommand citep
key "REINDERS201965,TAN2015493"
literal "false"

\end_inset

.
\end_layout

\begin_layout Itemize
Support Vector Machine algorithm is a powerful and versatile Machine Learning
 model, particularly well suited for classification of complex small- or
 medium-sized datasets.
 In this algorithm, the data is plotted in a n-dimensional space (number
 of features) and a decision boundary (hyperplane) split it into classes
 
\begin_inset CommandInset citation
LatexCommand citep
key "Geron2019,Harrington2012"
literal "false"

\end_inset

.
\end_layout

\begin_layout Itemize
Convolutional Neural Networks (CNNs) emerged from the study of the brain’s
 visual cortex, and they have been used in image recognition since the 1980s.
 The most important building block is the convolutional layer.
 The CNN´s architecture consists of several connected layers allowing the
 network to concentrate on small low-level features in the first hidden
 layer, then assemble them into larger higher-level features in the next
 layer, and so on 
\begin_inset CommandInset citation
LatexCommand citep
key "Geron2019"
literal "false"

\end_inset

.
\end_layout

\begin_layout Paragraph
Unsupervised learning
\end_layout

\begin_layout Standard
In unsupervised learning the training data is unlabeled.
 The system tries to learn without a teacher.
\end_layout

\begin_layout Standard
One of the most important unsupervised learning algorithms is k-means.
 K-means is a simple algorithm capable of clustering an unlabeled dataset
 very quickly and efficiently, often in just a few iterations.
 You have to specify the number of clusters k that the algorithm must find
 and it could easily label all the instances in the dataset by assigning
 each of them to the cluster whose centroid is closest 
\begin_inset CommandInset citation
LatexCommand citep
key "Geron2019"
literal "false"

\end_inset

.
\end_layout

\begin_layout Subsubsection
Dominant colors
\end_layout

\begin_layout Standard
The dominant colors refer to the principal colors presented in an image.
 After processing the image, the color of each pixel in it is represented
 by the RGB (Red, Green, Blue) additive color space.
\end_layout

\begin_layout Standard
This work and the vast majority of computer graphics applications use the
 RGB space because cathode ray computer monitors generate colors using those
 three components, red, green, and blue.
 In the RGB space, the light spectra of varying fractions of the three primary
 colors referred to as channels, combine to make new colors.
 Each channel has intensity values from 0 to 1 that are scaled by the number
 of bits used to represent each component.
 The 24-bit color cube used in this research has components in the range
 0–255.
 Each color in the color space can be represented as a three-value vector,
 for example (255, 127, 54) 
\begin_inset CommandInset citation
LatexCommand citep
key "Wallace2002"
literal "false"

\end_inset

.
\end_layout

\begin_layout Standard
Finally, the dominant colors of an image are selected grouping the image
 pixels in a certain number of k groups according to their color in the
 RGB color space.
 The average color of each group are the dominant colors and the number
 of pixels of that groups are the dominant colors´ percentage.
\end_layout

\begin_layout Subsubsection
Underlying technologies
\end_layout

\begin_layout Paragraph
Scikit learn
\end_layout

\begin_layout Standard
Scikit-learn is a Python module integrating a wide range of state-of-the-art
 machine learning algorithms for medium-scale supervised and unsupervised
 problems.
 This package focuses on bringing machine learning to non-specialists using
 a general-purpose high-level language.
 Emphasis is put on ease of use, performance, documentation, and API consistency.
 It has minimal dependencies and is distributed under the simplified BSD
 license, encouraging its use in both academic and commercial settings 
\begin_inset CommandInset citation
LatexCommand citep
key "scikit-learn"
literal "false"

\end_inset

.
\end_layout

\begin_layout Paragraph
Tensorflow
\end_layout

\begin_layout Standard
TensorFlow
\begin_inset Foot
status collapsed

\begin_layout Plain Layout
https://www.tensorflow.org
\end_layout

\end_inset

 is an open-source library developed by Google and has become very popular
 with Machine Learning.
 TensorFlow offers APIs that facilitates Machine Learning.
 TensorFlow also has a faster compilation time than other Deep Learning
 libraries such as Keras and Touch.
 TensorFlow supports both CPU and GPU computing devices 
\begin_inset CommandInset citation
LatexCommand citep
key "medium-TF"
literal "false"

\end_inset

.
\end_layout

\begin_layout Paragraph
Tensorflow Lite
\end_layout

\begin_layout Standard
TensorFlow Lite
\begin_inset Foot
status collapsed

\begin_layout Plain Layout
https://www.tensorflow.org/lite
\end_layout

\end_inset

 is a set of tools to help developers run TensorFlow models on mobile, embedded,
 and IoT devices.
 It enables on-device machine learning inference with low latency and a
 small binary size 
\begin_inset CommandInset citation
LatexCommand citep
key "TF-TFLite"
literal "false"

\end_inset

.
\end_layout

\begin_layout Standard
TensorFlow Lite consists of two main components:
\end_layout

\begin_layout Itemize
The TensorFlow Lite interpreter, which runs specially optimized models on
 many different hardware types, including mobile phones, embedded Linux
 devices, and microcontrollers.
\end_layout

\begin_layout Itemize
The TensorFlow Lite converter, which converts TensorFlow models into an
 efficient form for use by the interpreter, and can introduce optimizations
 to improve binary size and performance.
\end_layout

\begin_layout Paragraph
Swift
\end_layout

\begin_layout Standard
Swift
\begin_inset Foot
status collapsed

\begin_layout Plain Layout
https://swift.org
\end_layout

\end_inset

 is an open source programming language designed for macOS, iOS, watchOS,
 tvOS and beyond.
 Swift already supports all Apple platforms and Linux, with community members
 actively working to port to even more platforms 
\begin_inset CommandInset citation
LatexCommand citep
key "Apple-Swift"
literal "false"

\end_inset

.
 In 2010, Apple started developing Swift, a new programming language that
 would rival Objective-C in type safety, security, and hardware performance.
 Swift is more than 2.6x faster than Objective-C and more than 8.4x faster
 than Python.
 Swift 1.0 was released in September 2014 
\begin_inset CommandInset citation
LatexCommand citep
key "TechRep-Swift"
literal "false"

\end_inset

.
\end_layout

\begin_layout Paragraph
Xcode
\end_layout

\begin_layout Standard
Xcode
\begin_inset Foot
status collapsed

\begin_layout Plain Layout
https://developer.apple.com/xcode/
\end_layout

\end_inset

 is a long-standing tool for app production and a well-known integrated
 development environment (IDE), enabling developers to write the code and
 compile apps that can be used on a variety of different devices and operating
 systems 
\begin_inset CommandInset citation
LatexCommand citep
key "AInsider-Xcode"
literal "false"

\end_inset

.
 It also includes a unified macOS SDK and all the frameworks, compilers,
 debuggers, and other tools you need to build apps that run natively on
 Apple Silicon 
\begin_inset CommandInset citation
LatexCommand citep
key "Apple-Xcode"
literal "false"

\end_inset

.
\end_layout

\begin_layout Subsection
Related Work
\end_layout

\begin_layout Standard
Over the last decade, there has been considerable progress in developing
 methodologies based in machine learning for many of Earth Science applications
 
\begin_inset CommandInset citation
LatexCommand citep
key "Lary2018"
literal "false"

\end_inset

.
 Below are described some articles related with the implementation of machine
 learning in the classifcation of images into the geoscience field.
\end_layout

\begin_layout Subsubsection
Machine learning in geoscience
\end_layout

\begin_layout Standard
The following articles apply machine learning techniques to resolve problems
 in the classification and recognition of rock and mineral images.
\begin_inset Note Note
status open

\begin_layout Plain Layout
En esta sección coloqué todas los artículos relacionados.
 Aún no los he separado por temas ni colocado las falencias en ellos para
 dedicar el tiempo en avanzar la parte de resultados y también para asegurar
 primero que estos artículos sí se relacionan con el proyecto.
\end_layout

\end_inset


\begin_inset Note Note
status open

\begin_layout Plain Layout
In some of this articles I found about the 
\begin_inset Quotes eld
\end_inset

classification of rock lithology on geological surveys
\begin_inset Quotes erd
\end_inset

.
 However, I want to ask if it is a different type of rock classification
 than the used in this work.
 What do they mean by lithology?
\end_layout

\begin_layout Plain Layout
I searched in web but couldn´t understand.
 I just mentioned it in the articles below as rock classification.
\end_layout

\end_inset


\end_layout

\begin_layout Standard
In 
\begin_inset CommandInset citation
LatexCommand citep
key "Ran2019"
literal "false"

\end_inset

, Ran et al.
 also worked on the classification of rocks from images using machine learning.
 A total of 2290 images with typical rock characteristics of six rock types
 (granite, limestone, conglomerate, sandstone, shale, mylonite) were obtained
 from the Xingcheng Practical Teaching Base of Jilin University in Xingcheng,
 China.
 The images were labeled according to the clarity of the rock and were then
 cropped into 14,589 sample patches of 512 × 512 pixels compressed to 128
 × 128 pixels.
 60% of the patches of each type of rock were selected for the training
 dataset, 20% for the validation dataset, and 20% for the testing dataset.
 Finally, they proposed a deep CNNs model called RTCNNs that was compared
 with four machine learning models testing their effectiveness of classification
: SVM, AlexNet, GoogleLeNet Inception v3, and VGGNet-16.
 The proposed model achieved the highest overall accuracy of 97.76% compared
 with the other models.
\end_layout

\begin_layout Standard
In 
\begin_inset CommandInset citation
LatexCommand citep
key "Maitre2019"
literal "false"

\end_inset

, Maitre et al.
 worked on the automated recognition of mineral grains based on machine
 learning algorithms.
 An automated Scanning Electron Microscopy (SEM) was used to scan and assign
 a mineral specie to each grain of a sample surface, containing approximately
 27 different mineral species (plagioclase, augite, background, hypersthene,
 ilmenite, magnetite, titanite, hornblende, etc.) in diverse proportions,
 based on its chemical signature.
 This RGB picture was divided into 3192 sub-images of 600 × 600 pixels.
 Then, a large mosaic image was constructed with several views of the same
 surface taken with a stereo-zoom binocular microscope and also divided
 in 3192 sub-images of 600 × 600 pixels.
 Each image was segmented with the simple linear iterative clustering (SLIC)
 algorithm and the obtained superpixels were tagged with a class label according
 to the two predominant species showed in the SEM's scan.
 Finally, from each superpixel were extracted the coordinates of the first
 and second maximum peak in each RGB histogram utilizing 70% of the instances
 to train the supervised machine learning algorithms of K-Nearest Neighbors
 (KNN), Random Forest (RF), and Classification and Regression Trees (CART)
 and 30 % were used to test the effectiveness of the algorithms using the
 well-known indicators of the precision, recall, f1-score and the kappa
 statistics.
 The random forest algorithm gives the best results for the mineral species
 classification with a global accuracy improved at 89%.
\end_layout

\begin_layout Standard
In 
\begin_inset CommandInset citation
LatexCommand citep
key "Fan2020"
literal "false"

\end_inset

, Fan et al.
 created a classification method for rock recognition based on the two lightweig
ht CNNs, SqueezeNet and MobileNets combined with the transfer learning method.
 They utilized the dataset of the China Geological Survey that includes
 28 categories of rock images taken by a smartphone camera.
 A total of 3208 rock images were reduced to the size of 214 × 214 pixels:
 2566 images for the training set, 330 images for the validation set, and
 312 images for the test set.
 After, two models based on MobileNet and SqueezeNet and pretrained with
 ImageNet dataset were fine-tuned by the transfer learning method and trained
 with the rock images using four different batch sizes (8, 16, 32 and 48).
 Finally, a rock recognition software based on lightweight CNNs model was
 developed for Android devices.
 The CNNs models were analyzed in terms of their comparison with the standard
 convolutional network structure of ResNet50 heavyweight model achieving
 the occupation sizes of 19.6 M, 36.8 M, and 232.7 M for SqueezeNet, MobileNet
 and ResNet50, and SqueezeNet being the fastest with 7 times faster than
 ResNet50.
 On android smartphones SqueezeNet and MobileNet models were analyzed in
 terms of their space occupation, recognition accuracy and time obtaining:
 the file sizes of 9.2 MB and 17.6 MB, the recognition accuracies of 94.55%
 and 93.27%, and the execution time from 736 to 366 and 1218 to 523 millisecond
 respectively.
\end_layout

\begin_layout Standard
In 
\begin_inset CommandInset citation
LatexCommand citep
key "Cheng2017"
literal "false"

\end_inset

, Cheng and Guo proposed a Deep CNN to identify the rock granularity in
 rock images under the colour spaces of HSV, YCbCr and RGB.
 The rock images used were all feldspar sandstones collected from an oil
 field in Ordos, they are divided into three types: coarse feldspar sandstones,
 medium granular feldspar sandstone, and fine feldspar sandstone.
 There were 1600 RGB images of each type using 1200 as the training set,
 and the remaining 400 as the test set.
 All the images were normalized to 224 × 224 pixels and converted to YCbCr
 and HSV colour space.
 The proposed CNN structure is a 6-layer structure, 4 layers are convoluted
 and 2 layers are fully connected.
 The convolution layers use ReLU as the activation function and the fully
 connected layers do classification by the Softmax classifier.
 The experimental data is loaded into memory by a batch size of 100.
 Finally, the authors analyzed in terms of error rate different kernel sizes
 for the four convolutional layers (11-7-5-3, 11-5-3-3, and 11-3-3-3), tested
 the learning rates of 0.01, 0.001, 0.0005, 0.0001 for the best kernel sizes,
 and applied cross-validation with the YCbCr, HSV, and RGB colour spaces.
 The lowest error rates were obtained in the kernel sizes of 11-5-3-3 for
 the convolutional layers of the model, the 0.0005 learning rate, and the
 cross-validation of HSV color space.
 In RGB colour space, the classification accuracy achieves 98.5% with high
 efficiency.
\end_layout

\begin_layout Standard
In 
\begin_inset CommandInset citation
LatexCommand citep
key "Shoji2018"
literal "false"

\end_inset

, Shoji et al.
 created a machine learning model for quick and accurate rock recognition
 with smartphones.
 30 different kinds of rocks were collected from multiple locations in East
 China, and a total of 3,795 images were taken with sizes between 3M and
 6M.
 According to the ratio of 8:1:1, images were randomly selected from rock
 samples as the training data set, verification data set, and test data
 set.
 The parameters pretrained by ShuffleNet on the ImageNet data set were imported
 by the transfer learning method.
 In the training process, the default iteration step number was 3600, and
 the learning rate was 0.008.
 After training, the precision and running of the rock recognition model
 based on ShuffleNet were compared with other models.
 For the size of space occupied by the model, MobileNet, ShuffleNet, and
 SqueezeNet required 34.5M, 18.2M, and 25M, respectively, but 219.4M is needed
 for the ResNet50 model.
 Finally, an android application was created written in the Java programming
 language and runed on three android smartphones (Huawei, Samsung, and Oppo).
 The accuracy of the recognition model based no ShuffleNet reached 97.65%
 in the verification data set of PC and 95.30% on the test data set of the
 smartphone.
 The average recognition time of a single rock image was 786 milliseconds
 and the model size was only 18.2 MB.
\end_layout

\begin_layout Standard
In 
\begin_inset CommandInset citation
LatexCommand citep
key "Zhang2019"
literal "false"

\end_inset

, Zhang et al.
 worked on the intelligent identification for rock-mineral microscopic images
 using ensemble machine learning algorithms (model stacking).
 There were a total of 481 RGB images of four minerals: K-feldspar (Kf),
 perthite (Pe), plagioclase (Pl), and quartz (Qz or Q) obtained using the
 camera on the top of a microscope.
 Because the four minerals exist together with other minerals, the target
 images were cropped to cover them.
 After, the images were processed to be 299 × 299 pixels.
 The deep learning model based on Inception-v3 is adopted to extract high-level
 features of quartz and feldspar microscopic images.
 BBased on the extracted features, are generated by transfer learning using
 the Inception-v3 model.
 Based on the extracted features, logistic regression (LR), support vector
 machine (SVM), random forest (RF), k-nearest neighbors, multilayer perceptron
 (MLP), and gaussian naive Bayes (GNB) algorithms are applied to establish
 the models.
 LR, SVM, and MLP have a significant effect on extracted features, with
 higher accuracy (90.0%, 90.6%, and 89.8%) than the other models, for that
 reason, the new features generated by this three models are employed again
 in a new instance of LR for the model stacking.
 The result shows that the stacking model has a better performance than
 the single models, with an accuracy of 90.9%.
\end_layout

\begin_layout Standard
In [], the authors used deep learning for the automatic classification of
 plutonic rocks in android devices.
 The dataset contained 71 images of diorite, gabbro, granite, granodiorite,
 monzodiorite, and tonalite which classification was based on petrographic
 analysis of Cretaceous granitoids collected from Peru.
 In order to increase the number of images for training a dataset of 846
 images was generated from the first dataset with patches around 450 × 700
 pixels to 900 × 1000 pixels.
 A total of 423 images for training and 423 images for validation were used
 to train a deep neural network with 4-layer structure: two convolutional,
 and two fully connected layers.
 After each convolutional layer it is a max pooling layer of 2×2 size, and
 a flatten and a dropout of 50% layers were added before the fisrt and second
 fully conected layers respectively.
 Several combinations of rock classes were trained utilizing 100 epochs
 and abatch size of 32.
 The effectiveness of the model was evalueted in terms of precision, recall
 and f1-score to determine the best combination of rock classes.The best
 combination was with four classes of plutonic rocks (gabbro, diorite, granite
 and granodiorite) achieving an accuracy value of 95%, an average precision
 value of 96%, an average recall value of 453 95%, and an average F1 score
 value of 95%.
 Finnaly, an android applicaion was developed with the proposed model trained
 with the best cobination of rocks.
 The results of the application evaluation were: 70% for gabbro, 28.5% for
 diorite, 100% for granodiorite, and 28.5% for granite.
\end_layout

\begin_layout Section
Results
\end_layout

\begin_layout Subsection
Methodology
\end_layout

\begin_layout Standard
This section details each of the steps followed to obtain the best machine
 learning algorithm for the mobile application.
\end_layout

\begin_layout Subsubsection
Data description
\end_layout

\begin_layout Standard
The original images were provided by the Department of Earth and Biological
 Sciences, Loma Linda University.
 The dataset contains images of four classes of plutonic rocks: granite,
 granodiorite, gabbro, and diorite with a total of 81 images.
 The images used in the following experiments are available online
\begin_inset Foot
status collapsed

\begin_layout Plain Layout
https://github.com/sarah-hs/Color-extraction/tree/main/Rock-images
\end_layout

\end_inset

.
 Table 1 shows the number of images per class.
\end_layout

\begin_layout Standard
\begin_inset Float table
wide false
sideways false
status collapsed

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Number of images per class
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
centering
\end_layout

\begin_layout Plain Layout


\backslash
renewcommand{
\backslash
arraystretch}{1.1}
\end_layout

\begin_layout Plain Layout


\backslash
newrobustcmd{
\backslash
B}{
\backslash
bfseries}
\end_layout

\begin_layout Plain Layout


\backslash
begin{tabular}{|l|*{5}{c|}}
\backslash
hline
\end_layout

\begin_layout Plain Layout


\backslash
makebox[7em]{
\backslash
B Class} &
\backslash
makebox[7em]{
\backslash
B Number of images}
\backslash

\backslash

\end_layout

\begin_layout Plain Layout


\backslash
hline
\end_layout

\begin_layout Plain Layout

Granite & 16 
\backslash

\backslash

\end_layout

\begin_layout Plain Layout


\backslash
hline
\end_layout

\begin_layout Plain Layout

Granodiorite & 21 
\backslash

\backslash

\end_layout

\begin_layout Plain Layout


\backslash
hline
\end_layout

\begin_layout Plain Layout

Gabbro & 19 
\backslash

\backslash

\end_layout

\begin_layout Plain Layout


\backslash
hline
\end_layout

\begin_layout Plain Layout

Diorite & 25 
\backslash

\backslash

\end_layout

\begin_layout Plain Layout


\backslash
hline
\end_layout

\begin_layout Plain Layout


\backslash
B Total of images & 
\backslash
B 81 
\backslash

\backslash

\end_layout

\begin_layout Plain Layout


\backslash
hline
\end_layout

\begin_layout Plain Layout


\backslash
end{tabular}
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Subsubsection
Data preparation
\end_layout

\begin_layout Standard
In this step the images were processed to extract the color values from
 image pixels.
 The notebook with the source code is available online
\begin_inset Foot
status collapsed

\begin_layout Plain Layout
http://bit.ly/3pyh3JL
\end_layout

\end_inset

.
 In listing 1, the 
\begin_inset Quotes eld
\end_inset

load_images_from_folder
\begin_inset Quotes erd
\end_inset

 function showed in lines 6 to 18, is declared to process all the files
 with image extension ('.png', ’.jpg’, ’.pge’) from a folder.
 It also crops the images to a given size as shown in line 13 because we
 need all images to be the same size to train the machine learning algorithms.
\end_layout

\begin_layout Standard
\begin_inset CommandInset include
LatexCommand lstinputlisting
filename "Code/load images from folder.txt"
lstparams "language=Python,caption={Function to load images from a folder},label={load images from folder}"

\end_inset


\end_layout

\begin_layout Standard
In listing 2, the 
\begin_inset Quotes eld
\end_inset

load_images_from_directory
\begin_inset Quotes erd
\end_inset

 function is declared from lines 1 to 13 to iterate the subfolders contained
 in a main directory and process the images in them with the support of
 the previous declared 
\begin_inset Quotes eld
\end_inset

load_images_from_folder
\begin_inset Quotes erd
\end_inset

 function.
 It also assigns labels to the processed images according to the name of
 the folder in which they are as shown in line 9.
 For that reason it is important to group the images in subfolders based
 on their rock class name.
\end_layout

\begin_layout Standard
Finally, in line 17, the rock images in the folder declared in line 15 are
 processed and cropped to the size declared in line 16.
\end_layout

\begin_layout Standard
\begin_inset CommandInset include
LatexCommand lstinputlisting
filename "Code/load images from directory.txt"
lstparams "language=Python,caption={Function to load images from a directory},label={load images from directory}"

\end_inset


\end_layout

\begin_layout Subsubsection
Determining the best k number of clusters
\end_layout

\begin_layout Standard
The k-means algorithm was used to extract the dominant colors from the images.
 First, it was necessary to calculate the optimal number of clusters (groups
 of pixels with similar color) to use in the algorithm.
 In listing 3, the Elbow method is used for this purpose.
 This method consists of iterating in a range of possible cluster numbers
 to use in the k-means algorithm and determine the best number.
 In lines 4 to 9 it is iterated a cluster range between 2 and 20, at each
 iteration k-means is trained with the image data declared in line 1 and
 one of the cluster numbers.
 In lines 11 to 16 the score obtained with each number of cluster is plotted
 
\shape italic
\emph on
(see Fig.
 
\shape default
\emph default
2) and the number on the elbow of the plot is the best k number of clusters.
 For this experiment that number is 4.
\end_layout

\begin_layout Standard
\begin_inset CommandInset include
LatexCommand lstinputlisting
filename "Code/elbow method.txt"
lstparams "language=Python,caption={Determining the best number of clusters with the Elbow method},label={elbow method}"

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status collapsed

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Images/Elbow curve.png
	lyxscale 30
	width 100col%

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
The Elbow method showing the optimal k number of clusters
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Subsubsection
Color extraction
\end_layout

\begin_layout Standard
This step describes the process for extracting the dominant colors from
 the rock images.
\end_layout

\begin_layout Standard
In listing 4, the 
\begin_inset Quotes eld
\end_inset

get_dominant_colors
\begin_inset Quotes erd
\end_inset

 function was created.
 That function receives the pixel values of an image to train the k-means
 algorithm with 4 clusters, the number of clusters selected in the previous
 step.
 In line 6, k-means works by separating the pixels of that image into k
 groups (clusters) of similarly coloured pixels.
 The colors at each cluster center reflect the average of the attributes
 of all members of a cluster.
 The percentage of a cluster calculated in lines 8 to 10 is the number of
 pixels within that cluster.
 From lines 14 to 18 the center color in each cluster and its percentage
 is added to the features list that returns, in line 20, sixteen elements:
 the four main colors in RGB (red, green, and blue) color format and their
 percentage (see Fig.
 3).
\end_layout

\begin_layout Standard
\begin_inset CommandInset include
LatexCommand lstinputlisting
filename "Code/get dominant colors.txt"
lstparams "language=Python,caption={Function to extract the dominant colors from a single image},label={get dominant colors}"

\end_inset


\end_layout

\begin_layout Standard
In listing 5, the image data from the preparation step is iterated to extract
 the dominant colors with the previous explained 
\begin_inset Quotes eld
\end_inset

get_dominant_colors
\begin_inset Quotes erd
\end_inset

 function of listing 4.
 These colors are added to a new array called 
\begin_inset Quotes eld
\end_inset

extracted_colors
\begin_inset Quotes erd
\end_inset

.
 In line 6, the extracted colors are saved together with their respective
 rock label in a CSV file.
 This file is used in the next step to train the machine learning algorithms.
 The CSV is available online
\begin_inset Foot
status collapsed

\begin_layout Plain Layout
https://github.com/sarah-hs/Color-extraction/blob/main/colors.csv
\end_layout

\end_inset

.
\end_layout

\begin_layout Standard
\begin_inset CommandInset include
LatexCommand lstinputlisting
filename "Code/Iterate in data to extract colors.txt"
lstparams "language=Python,caption={Iterate original data to extract dominant colors},label={Iterate in data to extract colors}"

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status collapsed

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Images/Color extraction.png
	lyxscale 30
	width 100col%

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Dominant colors and average color of sample images
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Subsubsection
Training of the different algorithms
\end_layout

\begin_layout Standard
Five machine learning algorithms were trained for this experiment.
 They are Logistic Regression, K-Nearest Neighbors, Decision Trees, Support
 Vector Machines, and a Convolutional Neural Network.
 The notebook showing the training and validation process is also available
 online
\begin_inset Foot
status collapsed

\begin_layout Plain Layout
https://github.com/sarah-hs/Color-extraction/blob/main/ML-training.ipynb
\end_layout

\end_inset

.
\end_layout

\begin_layout Standard
First, in listing 6, the main dominant colors data is loaded from the CSV
 file of the previous step into x and y Numpy arrays and splitted into train,
 test and validation sets.
 The 
\begin_inset Quotes eld
\end_inset

train_test_split
\begin_inset Quotes erd
\end_inset

 function was used in line 9 to split the data and get a validation set
 with 20% of the data.
 In line 10, the other 80% of the split in line 9 was splitted again in
 20% for the test set and 80% for the train set.
 Three sets were used in the experiments: 20% for validation, 16% for testing,
 and 64% for training from the total of the data.
 The train set (
\begin_inset Quotes eld
\end_inset

xtrain
\begin_inset Quotes erd
\end_inset

 and 
\begin_inset Quotes eld
\end_inset

ytrain
\begin_inset Quotes erd
\end_inset

) was used to train all the algorithms.
\end_layout

\begin_layout Standard
\begin_inset CommandInset include
LatexCommand lstinputlisting
filename "Code/split data.txt"
lstparams "language=Python,caption={Splitting the data in train and test},label={split data in test and train}"

\end_inset


\end_layout

\begin_layout Standard
Below, listing 7 presents the training process and the parameters used for
 each algorithm.
\end_layout

\begin_layout Standard
Logistic Regression utilize in line 3 the Limited-memory Broyden–Fletcher–Goldfa
rb–Shanno (L-BFGS) solver parameter.
 This optimizer starts iterating at a random point (xt) to calculate a new
 point (xt+1) that is the minimum from the second derivate of original function
 at the starting point (xt).
 The new point will become the starting point for the next iteration.
 In this way, L-BFGS quickly converges on the solution 
\begin_inset CommandInset citation
LatexCommand citep
key "Dangeti2017"
literal "false"

\end_inset

.
\end_layout

\begin_layout Standard
K-Nearest-Neighbors was declared in line 8 with 3 n_neighbors.
 This number represents the number of neighbors used to classify a new sample
 into the class to which most of the neighbors belong.
\end_layout

\begin_layout Standard
Decision Trees algorithm was tuned specifying the class weights as 'balanced'
 in line 13.
 By utilizing class weights, we can increase the importance of a particular
 class and the balanced mode in class weight parameter uses the values of
 ytrain to automatically adjust the node weights inversely proportional
 to the class frequencies in the input data 
\begin_inset CommandInset citation
LatexCommand citep
key "Dangeti2017"
literal "false"

\end_inset

.
\end_layout

\begin_layout Standard
Support Vector Machines in line 18 was created with the Radial Basis Function
 (RBF) kernel to eliminate the computational requirement of the algorithm.
 Also the gamma value is used to scale the features when using the RBF kernel.
 This is very important because small gamma will give you low bias and high
 variance solutions.
 The 'auto' paramater is a small gamma represented by 
\begin_inset Formula $1/numberOfFeatures$
\end_inset

 
\begin_inset CommandInset citation
LatexCommand citep
key "Dangeti2017"
literal "false"

\end_inset

.
\end_layout

\begin_layout Standard
The Convolutional Neural Network was build as shown in lines 29 to 37.
 It was used two convolutional layers of one dimension with 32 filters and
 a kernel size of 2x2 in lines 29 and 30, a dropout layer of 50% in line
 31, a one dimension max pooling layer of 2x2 in line 32, and two fully
 connected layers in lines 34 and 35 with 100 connections the fisrt layer
 and the second with the number of rock classes used in this project that
 is 4.
 The model was compiled in line 36 with the ’categorical_crossentropy’ loss
 function used for categorical problem with more than 2 classes, and the
 'Adam' optimizer an computationally efficient optimization algorithm.
\end_layout

\begin_layout Standard
The training of each algortihm is listed in lines 4, 9, 14, 19, and 37 respectiv
ely.
 In order to train the convolutional neural network, it was necessary to
 try with several numbers of epochs and batches until the most optimal values
 were obtained as shown in line 37.
\end_layout

\begin_layout Standard
\begin_inset CommandInset include
LatexCommand lstinputlisting
filename "Code/train models.txt"
lstparams "language=Python,caption={Normalizing data and training models},label={train models}"

\end_inset


\end_layout

\begin_layout Subsubsection
Evaluation of the algorithms
\end_layout

\begin_layout Standard
Evaluating a model is a core part of building an effective machine learning
 project.
 For this purpose are used the following four metrics to evaluate the algorithms
 
\begin_inset CommandInset citation
LatexCommand citep
key "Mishra2018"
literal "false"

\end_inset

:
\end_layout

\begin_layout Itemize
Accuracy is the ratio of number of correct predictions to the total number
 of input samples.
\begin_inset Formula 
\[
Accuracy=\frac{CorrectPredictions}{PredictionsMade}
\]

\end_inset


\end_layout

\begin_layout Itemize
Precision is the number of correct positive results divided by the number
 of positive results predicted by the classifier.
\begin_inset Formula 
\[
Precision=\frac{TP}{TP+FP}
\]

\end_inset


\end_layout

\begin_layout Itemize
Recall is the number of correct positive results divided by the number of
 all relevant samples (all samples that should have been identified as positive).
 
\begin_inset Formula 
\[
Recall=\frac{TP}{TP+FN}
\]

\end_inset


\end_layout

\begin_layout Itemize
F1-score is used to measure a test’s accuracy, the Harmonic Mean between
 precision and recall.
 It tells you how precise your classifier is (how many instances it classifies
 correctly), as well as how robust it is (it does not miss a significant
 number of instances).
\begin_inset Formula 
\[
F1=2*\frac{Precision*Recall}{Precision+Recall}
\]

\end_inset

The greater the F1-score, the better is the performance of our model.
\end_layout

\begin_layout Standard
Table 2 shows the accuracy of all the trained algorithms evaluated with
 the test set of the previous step.
\end_layout

\begin_layout Standard
\begin_inset Float table
wide false
sideways false
status collapsed

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Results of the algorithms in terms of accuracy
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
centering
\end_layout

\begin_layout Plain Layout


\backslash
renewcommand{
\backslash
arraystretch}{1.1}
\end_layout

\begin_layout Plain Layout


\backslash
newrobustcmd{
\backslash
B}{
\backslash
bfseries}
\end_layout

\begin_layout Plain Layout


\backslash
begin{tabular}{|l|*{2}{c|}}
\backslash
hline
\end_layout

\begin_layout Plain Layout


\backslash
makebox[8em]{
\backslash
B Model} &
\backslash
makebox[3.5em]{
\backslash
B Accuracy} 
\backslash

\backslash

\end_layout

\begin_layout Plain Layout


\backslash
hline
\end_layout

\begin_layout Plain Layout

Logistic Regression & 0.29 
\backslash

\backslash

\end_layout

\begin_layout Plain Layout


\backslash
hline
\end_layout

\begin_layout Plain Layout

K-Nearest Neighbors & 0.82 
\backslash

\backslash

\end_layout

\begin_layout Plain Layout


\backslash
hline
\end_layout

\begin_layout Plain Layout

Decision Trees & 0.70 
\backslash

\backslash

\end_layout

\begin_layout Plain Layout


\backslash
hline
\end_layout

\begin_layout Plain Layout

Support Vector Machine & 0.41 
\backslash

\backslash

\end_layout

\begin_layout Plain Layout


\backslash
hline
\end_layout

\begin_layout Plain Layout

Convolutional Neural Network & 0.41 
\backslash

\backslash

\end_layout

\begin_layout Plain Layout


\backslash
hline
\end_layout

\begin_layout Plain Layout


\backslash
B Average & 
\backslash
B 0.52 
\backslash

\backslash

\end_layout

\begin_layout Plain Layout


\backslash
hline
\end_layout

\begin_layout Plain Layout


\backslash
end{tabular}
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
Tables 3-7 show the results of each model evaluation in terms of precision,
 recall and F1-score.
\end_layout

\begin_layout Standard
\begin_inset Float table
wide false
sideways false
status collapsed

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Results of Logistic Regression
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
centering
\end_layout

\begin_layout Plain Layout


\backslash
renewcommand{
\backslash
arraystretch}{1.1}
\end_layout

\begin_layout Plain Layout


\backslash
newrobustcmd{
\backslash
B}{
\backslash
bfseries}
\end_layout

\begin_layout Plain Layout


\backslash
begin{tabular}{|l|*{4}{c|}}
\backslash
hline
\end_layout

\begin_layout Plain Layout


\backslash
makebox[5em]{
\backslash
B Class} &
\backslash
makebox[5em]{
\backslash
B Precision} &
\backslash
makebox[5em]{
\backslash
B Recall} &
\backslash
makebox[5em]{
\backslash
B F1-Score}
\backslash

\backslash

\end_layout

\begin_layout Plain Layout


\backslash
hline
\end_layout

\begin_layout Plain Layout

Granite & 1.00 & 1.00 & 1.00 
\backslash

\backslash

\end_layout

\begin_layout Plain Layout


\backslash
hline
\end_layout

\begin_layout Plain Layout

Granodiorite & 0.86 & 1.00 & 0.92 
\backslash

\backslash

\end_layout

\begin_layout Plain Layout


\backslash
hline
\end_layout

\begin_layout Plain Layout

Gabbro &  0.50 & 1.00 & 0.67 
\backslash

\backslash

\end_layout

\begin_layout Plain Layout


\backslash
hline
\end_layout

\begin_layout Plain Layout

Diorite & 1.00 & 0.57 & 0.73 
\backslash

\backslash

\end_layout

\begin_layout Plain Layout


\backslash
hline
\end_layout

\begin_layout Plain Layout


\backslash
B Average & 
\backslash
B 0.84 & 
\backslash
B 0.89 & 
\backslash
B 0.83 
\backslash

\backslash

\end_layout

\begin_layout Plain Layout


\backslash
hline
\end_layout

\begin_layout Plain Layout


\backslash
end{tabular}
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Float table
wide false
sideways false
status collapsed

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Results of K-Nearest Neighbors
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
centering
\end_layout

\begin_layout Plain Layout


\backslash
renewcommand{
\backslash
arraystretch}{1.1}
\end_layout

\begin_layout Plain Layout


\backslash
newrobustcmd{
\backslash
B}{
\backslash
bfseries}
\end_layout

\begin_layout Plain Layout


\backslash
begin{tabular}{|l|*{4}{c|}}
\backslash
hline
\end_layout

\begin_layout Plain Layout


\backslash
makebox[5em]{
\backslash
B Class} &
\backslash
makebox[5em]{
\backslash
B Precision} &
\backslash
makebox[5em]{
\backslash
B Recall} &
\backslash
makebox[5em]{
\backslash
B F1-Score}
\backslash

\backslash

\end_layout

\begin_layout Plain Layout


\backslash
hline
\end_layout

\begin_layout Plain Layout

Granite & 1.00 & 1.00 & 1.00 
\backslash

\backslash

\end_layout

\begin_layout Plain Layout


\backslash
hline
\end_layout

\begin_layout Plain Layout

Granodiorite & 0.86 & 1.00 & 0.92 
\backslash

\backslash

\end_layout

\begin_layout Plain Layout


\backslash
hline
\end_layout

\begin_layout Plain Layout

Gabbro & 0.50 & 1.00 & 0.67 
\backslash

\backslash

\end_layout

\begin_layout Plain Layout


\backslash
hline
\end_layout

\begin_layout Plain Layout

Diorite & 1.00 & 0.57 & 0.73 
\backslash

\backslash

\end_layout

\begin_layout Plain Layout


\backslash
hline
\end_layout

\begin_layout Plain Layout


\backslash
B Average & 
\backslash
B 0.84 & 
\backslash
B 0.89 & 
\backslash
B 0.83 
\backslash

\backslash

\end_layout

\begin_layout Plain Layout


\backslash
hline
\end_layout

\begin_layout Plain Layout


\backslash
end{tabular}
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Float table
wide false
sideways false
status collapsed

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Results of Decision Trees
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
centering
\end_layout

\begin_layout Plain Layout


\backslash
renewcommand{
\backslash
arraystretch}{1.1}
\end_layout

\begin_layout Plain Layout


\backslash
newrobustcmd{
\backslash
B}{
\backslash
bfseries}
\end_layout

\begin_layout Plain Layout


\backslash
begin{tabular}{|l|*{4}{c|}}
\backslash
hline
\end_layout

\begin_layout Plain Layout


\backslash
makebox[5em]{
\backslash
B Class} &
\backslash
makebox[5em]{
\backslash
B Precision} &
\backslash
makebox[5em]{
\backslash
B Recall} &
\backslash
makebox[5em]{
\backslash
B F1-Score}
\backslash

\backslash

\end_layout

\begin_layout Plain Layout


\backslash
hline
\end_layout

\begin_layout Plain Layout

Granite & 1.00 & 0.50 & 0.67 
\backslash

\backslash

\end_layout

\begin_layout Plain Layout


\backslash
hline
\end_layout

\begin_layout Plain Layout

Granodiorite & 0.62 & 0.83 & 0.71 
\backslash

\backslash

\end_layout

\begin_layout Plain Layout


\backslash
hline
\end_layout

\begin_layout Plain Layout

Gabbro & 1.00 & 1.00 & 1.00 
\backslash

\backslash

\end_layout

\begin_layout Plain Layout


\backslash
hline
\end_layout

\begin_layout Plain Layout

Diorite & 0.67 & 0.57 & 0.62 
\backslash

\backslash

\end_layout

\begin_layout Plain Layout


\backslash
hline
\end_layout

\begin_layout Plain Layout


\backslash
B Average & 
\backslash
B 0.82 & 
\backslash
B 0.73 & 
\backslash
B 0.75 
\backslash

\backslash

\end_layout

\begin_layout Plain Layout


\backslash
hline
\end_layout

\begin_layout Plain Layout


\backslash
end{tabular}
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Float table
wide false
sideways false
status collapsed

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Results of Support Vector Machine
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
centering
\end_layout

\begin_layout Plain Layout


\backslash
renewcommand{
\backslash
arraystretch}{1.1}
\end_layout

\begin_layout Plain Layout


\backslash
newrobustcmd{
\backslash
B}{
\backslash
bfseries}
\end_layout

\begin_layout Plain Layout


\backslash
begin{tabular}{|l|*{4}{c|}}
\backslash
hline
\end_layout

\begin_layout Plain Layout


\backslash
makebox[5em]{
\backslash
B Class} &
\backslash
makebox[5em]{
\backslash
B Precision} &
\backslash
makebox[5em]{
\backslash
B Recall} &
\backslash
makebox[5em]{
\backslash
B F1-Score}
\backslash

\backslash

\end_layout

\begin_layout Plain Layout


\backslash
hline
\end_layout

\begin_layout Plain Layout

Granite & 0.50 & 0.50 & 0.50 
\backslash

\backslash

\end_layout

\begin_layout Plain Layout


\backslash
hline
\end_layout

\begin_layout Plain Layout

Granodiorite & 0.40 & 0.67 & 0.50 
\backslash

\backslash

\end_layout

\begin_layout Plain Layout


\backslash
hline
\end_layout

\begin_layout Plain Layout

Gabbro & 0.40 & 1.00 & 0.57 
\backslash

\backslash

\end_layout

\begin_layout Plain Layout


\backslash
hline
\end_layout

\begin_layout Plain Layout

Diorite & 0.00 & 0.00 & 0.00 
\backslash

\backslash

\end_layout

\begin_layout Plain Layout


\backslash
hline
\end_layout

\begin_layout Plain Layout


\backslash
B Average & 
\backslash
B 0.33 & 
\backslash
B 0.54 & 
\backslash
B 0.39 
\backslash

\backslash

\end_layout

\begin_layout Plain Layout


\backslash
hline
\end_layout

\begin_layout Plain Layout


\backslash
end{tabular}
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Float table
wide false
sideways false
status collapsed

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Results of Convolutional Neural Network
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
centering
\end_layout

\begin_layout Plain Layout


\backslash
renewcommand{
\backslash
arraystretch}{1.1}
\end_layout

\begin_layout Plain Layout


\backslash
newrobustcmd{
\backslash
B}{
\backslash
bfseries}
\end_layout

\begin_layout Plain Layout


\backslash
begin{tabular}{|l|*{4}{c|}}
\backslash
hline
\end_layout

\begin_layout Plain Layout


\backslash
makebox[5em]{
\backslash
B Class} &
\backslash
makebox[5em]{
\backslash
B Precision} &
\backslash
makebox[5em]{
\backslash
B Recall} &
\backslash
makebox[5em]{
\backslash
B F1-Score}
\backslash

\backslash

\end_layout

\begin_layout Plain Layout


\backslash
hline
\end_layout

\begin_layout Plain Layout

Granite & 0.00 & 0.00 & 0.00 
\backslash

\backslash

\end_layout

\begin_layout Plain Layout


\backslash
hline
\end_layout

\begin_layout Plain Layout

Granodiorite & 0.42 & 0.83 & 0.56 
\backslash

\backslash

\end_layout

\begin_layout Plain Layout


\backslash
hline
\end_layout

\begin_layout Plain Layout

Gabbro & 0.40 & 1.00 & 0.57 
\backslash

\backslash

\end_layout

\begin_layout Plain Layout


\backslash
hline
\end_layout

\begin_layout Plain Layout

Diorite & 0.00 & 0.00 & 0.00 
\backslash

\backslash

\end_layout

\begin_layout Plain Layout


\backslash
hline
\end_layout

\begin_layout Plain Layout


\backslash
B Average & 
\backslash
B 0.20 & 
\backslash
B 0.46 & 
\backslash
B 0.28 
\backslash

\backslash

\end_layout

\begin_layout Plain Layout


\backslash
hline
\end_layout

\begin_layout Plain Layout


\backslash
end{tabular}
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Subsection
Results
\end_layout

\begin_layout Standard
This section cover the creation process of a mobile application that classifies
 four types of plutonic rocks with the dominant colors extracted from images
 taken on iOS devices.
 
\end_layout

\begin_layout Standard
As it is shown in the 
\begin_inset Quotes eld
\end_inset

evaluation of the algorithms
\begin_inset Quotes erd
\end_inset

 step from methodology, the algorithm with the best evaluation results was
 K-Nearest Neighbors.
 It was the algorithm implemented in the mobile application.
\end_layout

\begin_layout Standard
To develope the iOS application were used the following pod dependencies:
\end_layout

\begin_layout Itemize
The TensorFlowLite pod from Tensorflow is a dependency that allows to read
 an exported machine learning model from a 'tflite' file when the application
 starts.
 This way, the model can be used for classification.
\end_layout

\begin_layout Itemize
An adaptation of the DominantColor pod from Indragie Karunaratne.
 This dependency implements K-means algorithm to extract the dominant colors
 of new images in real-time with Swift, the language to develope iOS and
 macOS applications.
 It allows the exported model to classify rocks with the dominant colors.
\end_layout

\begin_layout Standard
The application works the classification with three main Swift files: ViewContro
ller.swift, ImageClassifier.swift, and DominantColors.swift.
 The source code of the application is available online
\begin_inset Foot
status collapsed

\begin_layout Plain Layout
https://github.com/sarah-hs/Rock-Classifer-iOS
\end_layout

\end_inset

.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement t
wide true
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Images/Workflow.png
	lyxscale 50
	width 80page%

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Application workflow
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Paragraph
View controller
\end_layout

\begin_layout Standard
This file is the link between the user view and the ImageClassifier class.
\end_layout

\begin_layout Standard
The following variables were used in the ViewController visualize the image
 and send it to the .
\end_layout

\begin_layout Standard
\begin_inset CommandInset include
LatexCommand lstinputlisting
filename "Code/ViewController.txt"
lstparams "escapeinside={*}{*},language=bash,morekeywords={class, static, enum,typealias,private,var,guard,func,init,self,try,switch,fileprivate},keywordsprefix={@},caption={ViewController.swift},label={View Controller}"

\end_inset


\end_layout

\begin_layout Paragraph
Image classifier
\end_layout

\begin_layout Standard
As shown in listing 9...
\end_layout

\begin_layout Standard
\begin_inset CommandInset include
LatexCommand lstinputlisting
filename "Code/ImageClassifier.txt"
lstparams "escapeinside={*}{*},language=bash,morekeywords={class, static, enum,typealias,private,var,guard,func,init,self,try,switch,fileprivate},keywordsprefix={@},caption={ImageClassifier.swift},label={Image Classifier}"

\end_inset


\end_layout

\begin_layout Paragraph
Dominant colors
\end_layout

\begin_layout Standard
HEre was used a function..
\end_layout

\begin_layout Standard
\begin_inset CommandInset include
LatexCommand lstinputlisting
filename "Code/DominantColors.txt"
lstparams "escapeinside={*}{*},language=bash,morekeywords={class, static, enum,typealias,private,var,guard,func,init,self,try,switch,fileprivate},keywordsprefix={@},caption={DominantColors.swift},label={Dominant Colors}"

\end_inset


\end_layout

\begin_layout Subsection
Discussion
\end_layout

\begin_layout Standard
Five machine learning algorithms were trained with just the four dominant
 colors extracted from rock images.
 The best algorithm in this experiment was K-Nearest Neighbors with an accuracy
 of 82%.
 Its values for precision, recall, and F1 score were 84%, 89%, and 83%.
 After obtain the best suited algorithm for rock classification with dominant
 colors, an iOS mobile application was developed to classify rock images
 into four classes of plutonic rocks (granite, granodioorite, gabbro and
 diorite).
 This application also allows the user to visualize the dominant colors
 and the average color in new images and detect changes in rock colors.
\end_layout

\begin_layout Section
Conclusions and Future Work
\end_layout

\begin_layout Standard
\begin_inset Note Note
status collapsed

\begin_layout Plain Layout
\begin_inset Newpage clearpage
\end_inset


\end_layout

\end_inset


\begin_inset Note Note
status collapsed

\begin_layout Plain Layout
\begin_inset Newpage pagebreak
\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset CommandInset bibtex
LatexCommand bibtex
btprint "btPrintCited"
bibfiles "Rocks"
options "bibtotoc"

\end_inset


\end_layout

\end_body
\end_document
