#LyX 2.3 created this file. For more info see http://www.lyx.org/
\lyxformat 544
\begin_document
\begin_header
\save_transient_properties true
\origin unavailable
\textclass IEEEtran
\begin_preamble
% for subfigures/subtables
\usepackage{titlesec}
\titlespacing{\subsubsection}{0pt}{0.6em}{0pt}
\usepackage[caption=false,font=footnotesize]{subfig}
\usepackage{diagbox}
\usepackage{array}
\usepackage{listings}
\lstdefinelanguage{Swift}{language=bash,morekeywords={fix},}
\usepackage{color}
\definecolor{lightgray}{RGB}{246,246,246}
\definecolor{darkgray}{RGB}{128,128,128}
\end_preamble
\options journal
\use_default_options false
\begin_modules
graphicboxes
\end_modules
\maintain_unincluded_children false
\language english
\language_package default
\inputencoding ascii
\fontencoding global
\font_roman "default" "default"
\font_sans "default" "default"
\font_typewriter "default" "default"
\font_math "auto" "auto"
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100 100
\font_tt_scale 100 100
\use_microtype false
\use_dash_ligatures true
\graphics default
\default_output_format default
\output_sync 1
\bibtex_command bibtex
\index_command default
\float_placement H
\paperfontsize default
\spacing single
\use_hyperref true
\pdf_title "Your Title"
\pdf_author "Your Name"
\pdf_bookmarks true
\pdf_bookmarksnumbered true
\pdf_bookmarksopen true
\pdf_bookmarksopenlevel 1
\pdf_breaklinks false
\pdf_pdfborder true
\pdf_colorlinks false
\pdf_backref false
\pdf_pdfusetitle false
\pdf_quoted_options "pdfpagelayout=OneColumn, pdfnewwindow=true, pdfstartview=XYZ, plainpages=false"
\papersize default
\use_geometry false
\use_package amsmath 1
\use_package amssymb 1
\use_package cancel 0
\use_package esint 0
\use_package mathdots 1
\use_package mathtools 0
\use_package mhchem 1
\use_package stackrel 0
\use_package stmaryrd 0
\use_package undertilde 0
\cite_engine biblatex-natbib
\cite_engine_type numerical
\biblio_style jurabib
\biblatex_bibstyle ieee
\biblatex_citestyle numeric
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\justification true
\use_refstyle 0
\use_minted 0
\index Index
\shortcut idx
\color #008000
\end_index
\secnumdepth 3
\tocdepth 3
\paragraph_separation indent
\paragraph_indentation default
\is_math_indent 0
\math_numbering_side default
\quotes_style english
\dynamic_quotes 0
\papercolumns 2
\papersides 1
\paperpagestyle default
\listings_params "breaklines=true,captionpos=b,aboveskip=3mm,belowskip=3mm,showstringspaces=false,columns=flexible,basicstyle={\scriptsize\ttfamily},breakatwhitespace=true,numbers=left,numberstyle={\scriptsize\ttfamily},xleftmargin={0.7cm},framexleftmargin={0.7em},numbersep=8pt,tabsize=3,backgroundcolor={\color{lightgray}},commentstyle={\color{darkgray}}"
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Standard
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
begin{titlepage}
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\align left
\begin_inset Float figure
wide false
sideways false
status collapsed

\begin_layout Plain Layout
\align left
\begin_inset Graphics
	filename Images/Logo_UM.png
	lyxscale 7
	width 2.5cm
	height 2.5cm
	keepAspectRatio

\end_inset


\begin_inset space \hspace{}
\length 12cm
\end_inset


\begin_inset Graphics
	filename Images/Logo_FIT.png
	lyxscale 75
	width 2.5cm
	height 2.5cm
	keepAspectRatio

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
\align center

\series bold
\size huge
Universidad de Montemorelos
\end_layout

\begin_layout Standard

\series bold
\size larger
\begin_inset VSpace 0.8cm
\end_inset


\end_layout

\begin_layout Standard
\align center

\series bold
\size larger
Facultad de Ingeniería y Tecnología
\end_layout

\begin_layout Standard
\align center

\series bold
\size larger
Ingeniería en Sistemas Computacionales
\end_layout

\begin_layout Standard

\series bold
\size larger
\begin_inset VSpace 1.4cm
\end_inset


\end_layout

\begin_layout Standard
\align center

\series bold
\size huge
Automatic classification of plutonic rocks with machine learning applied
 to extracted colors on iOS devices
\end_layout

\begin_layout Standard

\series bold
\size larger
\begin_inset VSpace 1.4cm
\end_inset


\end_layout

\begin_layout Standard
\align center

\series bold
\size larger
Sarah Hernández Serrano
\end_layout

\begin_layout Standard
\align center

\series bold
\size larger
1170469
\end_layout

\begin_layout Standard

\series bold
\size larger
\begin_inset VSpace 1.4cm
\end_inset


\end_layout

\begin_layout Standard
\align center

\series bold
\size larger
Asesor: Dr.
 Germán Harvey Alférez Salinas
\end_layout

\begin_layout Standard
\align center

\series bold
\size larger
Co-asesores: Dr.
 Benjamin Clausen and Dra.
 Ana María Martínez Ardila
\end_layout

\begin_layout Standard

\series bold
\size larger
\begin_inset VSpace 1.4cm
\end_inset


\end_layout

\begin_layout Standard
\align center

\series bold
\size larger
Montemorelos, Nuevo León, México
\end_layout

\begin_layout Standard
\align center

\series bold
\size larger
00 de mayo de 2021
\end_layout

\begin_layout Standard
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
end{titlepage}
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Newpage pagebreak
\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
begin{titlepage}
\end_layout

\end_inset


\end_layout

\begin_layout Standard

\series bold
\size larger
\begin_inset VSpace 7cm
\end_inset


\end_layout

\begin_layout Abstract
The classification of different rocks can provide important information
 about the conditions under they were formed and their tectonic environment.
 Color is a key property for rock classification.
 However, it is difficult to describe them because perceived colors in rocks
 also depend on the observer's experience with similar observations.
 Moreover, the equipment for rock classification is expensive, which makes
 this equipment prohibitive to geology students and amateurs.
 The contribution of this research work is twofold.
 First, since color is a key property for rock classification, feature reduction
 was applied in rock images extracting just the four dominant colors before
 training the machine learning algorithms; to this end, the k-means clustering
 method was used.
 Second, we present an iOS application that uses machine learning to classify
 images of the following plutonic rocks: granite, granodiorite, gabbro,
 and diorite.
 Different machine learning models were created and evaluated with the Logistic
 Regression, K-Nearest Neighbors, Decision Trees, Support Vector Machine,
 and Convolutional Neural Network algorithms.
 The best results were achieved with K-Nearest Neighbors algorithm.
 The evaluation results of the algorithm are the following: 82% of accuracy,
 84% of precision, 89% of recall, and 83% of F1-score.
\end_layout

\begin_layout Keywords
Machine Learning, Color Extraction, iOS Devices, Geology, Rock Classification,
 Features Reduction, Dominant Colors, K-means Clustering, Logistic Regression,
 K-Nearest Neighbors, Support Vector Machine, Convolutional Neural Network,
 Decision Trees.
\end_layout

\begin_layout Standard
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
end{titlepage}
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Newpage pagebreak
\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
begin{titlepage}
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset CommandInset toc
LatexCommand tableofcontents

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
end{titlepage}
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Newpage pagebreak
\end_inset


\end_layout

\begin_layout Title
Automatic classification of plutonic rocks with machine learning applied
 to extracted colors on iOS devices
\end_layout

\begin_layout Author
Sarah
\begin_inset space ~
\end_inset

Hernández,
\begin_inset space ~
\end_inset

Germán
\begin_inset space ~
\end_inset

H.
\begin_inset space ~
\end_inset

Alférez,
\begin_inset space ~
\end_inset

Benjamin
\begin_inset space ~
\end_inset

Clausen
\begin_inset space ~
\end_inset

and
\begin_inset space ~
\end_inset

Ana
\begin_inset space ~
\end_inset

M.
\begin_inset space ~
\end_inset

Martínez 
\begin_inset Foot
status open

\begin_layout Plain Layout
Sarah
\begin_inset space ~
\end_inset

Hernández is a computer science engineering student at the School of Engineering
 and Technology of Montemorelos University, Nuevo León, Mexico, e-mail:
 
\begin_inset CommandInset href
LatexCommand href
target "1170469@alumno.um.edu.mx"
type "mailto:"
literal "false"

\end_inset

.
\end_layout

\end_inset


\begin_inset Foot
status open

\begin_layout Plain Layout
Germán H.
 Alferez, Ph.D., is the director of the Institute of Data Science and professor
 at the School of Engineering and Technology of Montemorelos University,
 Nuevo León, Mexico, e-mail: 
\begin_inset CommandInset href
LatexCommand href
target "harveyalferez@um.edu.mx"
type "mailto:"
literal "false"

\end_inset

.
\end_layout

\end_inset


\begin_inset Foot
status open

\begin_layout Plain Layout
Benjamin Clausen, Ph.D., is a professor at the Department of Earth and Biological
 Sciences of Loma Linda University, California, United States, e-mail: 
\begin_inset CommandInset href
LatexCommand href
target "bclausen@llu.edu"
literal "false"

\end_inset

.
\end_layout

\end_inset


\begin_inset Foot
status open

\begin_layout Plain Layout
Ana M.
 Martínez, Ph.D., is a professor at the Department of Earth and Biological
 Sciences of Loma Linda University, California, United States, e-mail: 
\begin_inset CommandInset href
LatexCommand href
target "anmartinez@llu.edu"
literal "false"

\end_inset

.
\end_layout

\end_inset


\end_layout

\begin_layout Special Paper Notice
School of Engineering and Technology, Montemorelos University, Mexico
\end_layout

\begin_layout Section
Introduction
\end_layout

\begin_layout Subsection
Background
\end_layout

\begin_layout Standard
\begin_inset Flex Paragraph Start
status open

\begin_layout Plain Layout
\begin_inset Argument 1
status open

\begin_layout Plain Layout
T
\end_layout

\end_inset


\end_layout

\end_inset

he classification of different rocks can provide important information about
 the conditions under which they were formed.
 They can also tell us much about their tectonic environment, given that
 they are closely linked to the convection of tectonic plates.
 Their mineral and chemical makeup can be used to learn about the composition,
 temperature and pressure that exists within the Earth’s mantle 
\begin_inset CommandInset citation
LatexCommand citep
key "Williams-2015"
literal "false"

\end_inset

.
\end_layout

\begin_layout Standard
Plutonic rocks are a type of igneous rock (one of the three main types of
 rocks in the world and also the most common) formed when magma in the middle
 of the volcano cools and solidifies below the Earth’s surface.
 They come in many different sizes and colors, and have a wide variety of
 uses 
\begin_inset CommandInset citation
LatexCommand citep
key "NGS-2019,Study-2013"
literal "false"

\end_inset

.
\end_layout

\begin_layout Standard
Our contribution is twofold: extract the dominant colors of plutonic rock
 images and use these information to classify them with the implemention
 of machine learning.
 Color changes in rocks may indicate changes in the rock’s mineral assemblage,
 texture, organic carbon content (shales), or other properties 
\begin_inset CommandInset citation
LatexCommand citep
key "NRCS-2012"
literal "false"

\end_inset

.
 That is why color is a key property for rock classification.
 In addition, machine learning, a branch of artificial intelligence, provides
 easy classification of images whitin mobile applications and is becoming
 an appealing tool in various fields of earth sciences, especially in prediction
s and resources estimation 
\begin_inset CommandInset citation
LatexCommand citep
key "Cate2017"
literal "false"

\end_inset

.
\end_layout

\begin_layout Standard
A previous work has be done by Elías L.
 Vázquez and Germán H.
 Alférez for the classification of [].
 
\begin_inset Note Note
status open

\begin_layout Plain Layout
descripción del trabajo de Elías.
\end_layout

\end_inset


\end_layout

\begin_layout Subsection
Problem Statement
\end_layout

\begin_layout Standard
The equipment for rock classification is expensive, which makes it prohibitive
 to geology students and amateurs.
 In addtion, despite the fact that color is a key property for rock classificati
on, it is an attribute difficult to describe because perceived colors in
 rocks also depend on the stimulus area and the observer's experience with
 similar observations; so a color may often be named differently by different
 persons 
\begin_inset CommandInset citation
LatexCommand citep
key "NRCS-2012"
literal "false"

\end_inset

.
\end_layout

\begin_layout Subsection
Justification
\end_layout

\begin_layout Standard
There are two reasons to create an iOS mobile application that allows the
 classification of rocks through colors with machine learning.
 First, no such application exists.
 A mobile application offers the flexibility to carry out the classification
 on real time and could be an alternative to expensive traditional methods
 of rock classification.
 Second, the extraction of the dominant colors allows geologists to more
 accurately detect color changes in rocks and is useful to reduce the number
 of features in images used to train machine learning, which provides easy
 classification of rocks within the application.
\end_layout

\begin_layout Subsection
Objectives
\end_layout

\begin_layout Standard
The main objective of this research work is to create an iOS application
 that uses machine learning to extract the dominant colors from images and
 use these colors to classify plutonic rocks.
 This objective is achieved with the following sub-objectives:
\end_layout

\begin_layout Itemize
Determine the best k number of clusters to use in the k-means clustering
 machine learning method to extract the dominant colors from images of plutonic
 rocks.
\end_layout

\begin_layout Itemize
Use the extracted dominant colors and the percentage of pixels belonging
 to each color cluster as the input to train the following machine learning
 algorithms: Logistic regression (LR), K-Nearest Neighbors (KNN), Decision
 Trees (DT), Support Vector Machine (SVM), and a Convolutional Neural Network
 (CNN).
\end_layout

\begin_layout Itemize
Validate the models generated to get the best suited to deploy the best
 model on the iOS mobile application.
\end_layout

\begin_layout Itemize
Test the effectiveness of the application with images taken from new plutonic
 rocks to compare the results with our previous work in which a CNN was
 trained with images using the whole set of features.
 
\end_layout

\begin_layout Subsection
Hypothesis
\end_layout

\begin_layout Standard
The training of a machine learning model with just the dominant colors extracted
 from rock images can provide an effective way for the classification of
 plutonic rock images.
\end_layout

\begin_layout Section
Theoretical Foundation
\end_layout

\begin_layout Subsection
Underpinnings of our Approach
\end_layout

\begin_layout Standard
Our approach is based on the following concepts 
\shape italic
\emph on
(see Fig.
 1
\shape default
\emph default
).
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status collapsed

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Images/Map of concepts.png
	lyxscale 20
	width 100col%

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Underpinnings of our approach
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Subsubsection
Plutonic rocks
\end_layout

\begin_layout Standard
Plutonic rocks are solidified inside the earth’s crust, usually from magma,
 although they may have been formed by a different mechanism.
 Plutonic rocks are generally coarse-grained, but not all coarse-grained
 rocks are plutonic 
\begin_inset CommandInset citation
LatexCommand citep
key "RACEFEN-gg"
literal "false"

\end_inset

.
\end_layout

\begin_layout Standard
According to 
\begin_inset CommandInset citation
LatexCommand citep
key "RACEFEN-gg"
literal "false"

\end_inset

, granite rocks are plutonic rocks with a granular texture, composed of
 similar amounts of quartz, potassium feldspar, and plagioclase as essential
 minerals, and smaller amounts of one or more minerals, such as biotite,
 muscovite or hornblende.
\end_layout

\begin_layout Standard
Granodiorite is a plutonic rock of the granitoid family, characterized by
 quartz because plagioclase constitutes more than 2/3 of the total feldspars.
 Generally, together with granite, it is the most abundant rock of the great
 batholiths.
 Its volcanic equivalent is dacite.
 Granodiorite is similar to granite, but with less potassium feldspar and
 more plagioclase.
\end_layout

\begin_layout Standard
Gabbro is a plutonic rock composed mainly of calcium plagioclase and clinopyroxe
ne or orthopiroxene, with or without olivine or amphibole.
 It is the intrusive equivalent of basalt.
 It is distinguished from diorite by the nature of plagioclase, which is
 higher in calcium than in sodium.
\end_layout

\begin_layout Standard
Diorite has about the same structural properties as granite but darker colour
 and more limited supply.
 Commonly is composed of about two-thirds plagioclase feldspar and one-third
 dark-coloured minerals, such as hornblende or biotite.
 The presence of sodium-rich feldspar, oligoclase or andesine, in contrast
 to calcium-rich plagioclase, labradorite or bytownite, is the main distinction
 between diorite and gabbro 
\begin_inset CommandInset citation
LatexCommand citep
key "Britannica-Diorite"
literal "false"

\end_inset

.
\end_layout

\begin_layout Subsubsection
Machine Learning
\end_layout

\begin_layout Standard
Machine learning is a branch of artificial intelligence that lies at the
 intersection of computer science, engineering, and statistics and often
 appears in other disciplines.
 Machine Learning systems can be classified according to the type of supervision
 they get during training 
\begin_inset CommandInset citation
LatexCommand citep
key "Harrington2012,Geron2019"
literal "false"

\end_inset

.
 In this way, there are two major categories:
\end_layout

\begin_layout Paragraph
Supervised learning
\end_layout

\begin_layout Standard
In supervised learning, the training set fed to the algorithm includes the
 desired solutions, called labels.
 A typical supervised learning task is classification 
\begin_inset CommandInset citation
LatexCommand citep
key "Geron2019"
literal "false"

\end_inset

.
\end_layout

\begin_layout Standard
Some common algorithms of supervised learning are described as follows:
\end_layout

\begin_layout Itemize
Logistic Regression (LR) is commonly used to estimate the probability of
 an instance to belong to a particular class.
 This model computes a weighted sum of the input features (plus a bias term)
 and outputs the logistic of this result.
 The logistic is a sigmoid function that outputs a number between 0 and
 1.
 This makes it a binary classifier 
\begin_inset CommandInset citation
LatexCommand citep
key "Geron2019"
literal "false"

\end_inset

.
\end_layout

\begin_layout Itemize
K-Nearest Neighbors (KNN) is a simple algorithm in which its priniciple
 is to find a predefined number of training samples closest in distance
 to the new point, and predict the label from these.
 Being a non-parametric method, it is often successful in classification
 situations where the decision boundary is very irregular 
\begin_inset CommandInset citation
LatexCommand citep
key "sklearn-KNN"
literal "false"

\end_inset

.
\end_layout

\begin_layout Itemize
Decision Trees (DT) algorithm consists of split nodes and leaf nodes.
 Each split node performs a split decision and routes a data sample either
 to the left or the right child node.
 In the tree structures, leaves represent the labels, non-leaf nodes are
 the input features, and branches represent conjunctions of features that
 lead to the classifications 
\begin_inset CommandInset citation
LatexCommand citep
key "REINDERS201965,TAN2015493"
literal "false"

\end_inset

.
\end_layout

\begin_layout Itemize
Support Vector Machine (SVM) algorithm is a powerful and versatile machine
 learning model, particularly well suited for classification of complex
 small- or medium-sized datasets.
 In this algorithm, the data is plotted in a n-dimensional space (number
 of features) and a decision boundary (hyperplane) split it into classes
 
\begin_inset CommandInset citation
LatexCommand citep
key "Geron2019,Harrington2012"
literal "false"

\end_inset

.
\end_layout

\begin_layout Itemize
Convolutional Neural Networks (CNNs) emerged from the study of the brain’s
 visual cortex.
 The most important building block is the convolutional layer.
 The CNN´s architecture consists of several connected layers allowing the
 network to concentrate on small low-level features in the first hidden
 layer, then assemble them into larger higher-level features in the next
 layer, and so on 
\begin_inset CommandInset citation
LatexCommand citep
key "Geron2019"
literal "false"

\end_inset

.
\end_layout

\begin_layout Paragraph
Unsupervised learning
\end_layout

\begin_layout Standard
In unsupervised learning the training data is unlabeled.
 One of the most important unsupervised learning algorithms is k-means.
 K-means is a simple algorithm capable of clustering an unlabeled dataset
 very quickly and efficiently, often in just a few iterations.
 You have to specify the number of clusters k that the algorithm must find
 and it could easily label all the instances in the dataset by assigning
 each of them to the cluster whose centroid is closest 
\begin_inset CommandInset citation
LatexCommand citep
key "Geron2019"
literal "false"

\end_inset

.
\end_layout

\begin_layout Subsubsection
Dominant colors
\end_layout

\begin_layout Standard
The dominant colors refer to the principal colors presented in an image.
 After processing the image, the color of each pixel in it is represented
 by the RGB (Red, Green, Blue) additive color space.
\end_layout

\begin_layout Standard
In the RGB space, the light spectra of varying fractions of the three primary
 colors referred to as channels, combine to make new colors.
 Each channel has intensity values from 0 to 1 that are scaled by the number
 of bits used to represent each component.
 The 24-bit color cube used in this research has components in the range
 of 0–255.
 Each color in the color space can be represented as a three-value vector
 
\begin_inset CommandInset citation
LatexCommand citep
key "Wallace2002"
literal "false"

\end_inset

.
\end_layout

\begin_layout Subsubsection
Underlying technologies
\end_layout

\begin_layout Paragraph
Scikit learn
\end_layout

\begin_layout Standard
Scikit-learn is a Python module that integrates a wide range of state-of-the-art
 machine learning algorithms for medium-scale supervised and unsupervised
 problems.
 This package focuses on bringing machine learning to non-specialists using
 a general-purpose high-level language.
 Emphasis is put on ease of use, performance, documentation, and API consistency.
 It has minimal dependencies and is distributed under the simplified BSD
 license, encouraging its use in both academic and commercial settings 
\begin_inset CommandInset citation
LatexCommand citep
key "scikit-learn"
literal "false"

\end_inset

.
\end_layout

\begin_layout Paragraph
Tensorflow
\end_layout

\begin_layout Standard
TensorFlow
\begin_inset Foot
status collapsed

\begin_layout Plain Layout
https://www.tensorflow.org
\end_layout

\end_inset

 is an open-source library developed by Google.
 It has become very popular because it provides APIs that facilitates machine
 learning.
 TensorFlow also has a faster compilation time than other deep learning
 libraries such as Keras and Touch.
 TensorFlow supports both CPU and GPU computing devices 
\begin_inset CommandInset citation
LatexCommand citep
key "medium-TF"
literal "false"

\end_inset

.
\end_layout

\begin_layout Paragraph
Tensorflow Lite
\end_layout

\begin_layout Standard
TensorFlow Lite
\begin_inset Foot
status collapsed

\begin_layout Plain Layout
https://www.tensorflow.org/lite
\end_layout

\end_inset

 is a set of tools to help developers run TensorFlow models on mobile, embedded,
 and IoT devices.
 It enables on-device machine learning inference with low latency and a
 small binary size 
\begin_inset CommandInset citation
LatexCommand citep
key "TF-TFLite"
literal "false"

\end_inset

.
\end_layout

\begin_layout Standard
TensorFlow Lite consists of two main components:
\end_layout

\begin_layout Itemize
The TensorFlow Lite interpreter, which runs specially optimized models on
 many different hardware types, including mobile phones, embedded Linux
 devices, and microcontrollers.
\end_layout

\begin_layout Itemize
The TensorFlow Lite converter, which converts TensorFlow models into an
 efficient form for use by the interpreter, and can introduce optimizations
 to improve binary size and performance.
\end_layout

\begin_layout Paragraph
Swift
\end_layout

\begin_layout Standard
Swift
\begin_inset Foot
status collapsed

\begin_layout Plain Layout
https://swift.org
\end_layout

\end_inset

 is an open source programming language designed for macOS, iOS, watchOS,
 tvOS, and more.
 Swift already supports all Apple platforms and Linux, with community members
 actively working to port to even more platforms 
\begin_inset CommandInset citation
LatexCommand citep
key "Apple-Swift"
literal "false"

\end_inset

.
 In 2010, Apple started developing Swift, a new programming language that
 would rival Objective-C in type safety, security, and hardware performance.
 Swift is more than 2.6x faster than Objective-C and more than 8.4x faster
 than Python.
 Swift 1.0 was released in September 2014 
\begin_inset CommandInset citation
LatexCommand citep
key "TechRep-Swift"
literal "false"

\end_inset

.
\end_layout

\begin_layout Paragraph
Xcode
\end_layout

\begin_layout Standard
Xcode
\begin_inset Foot
status collapsed

\begin_layout Plain Layout
https://developer.apple.com/xcode/
\end_layout

\end_inset

 is a long-standing tool for app production and a well-known integrated
 development environment (IDE), enabling developers to write the code and
 compile apps that can be used on a variety of different devices and operating
 systems 
\begin_inset CommandInset citation
LatexCommand citep
key "AInsider-Xcode"
literal "false"

\end_inset

.
 It also includes a unified macOS SDK and all the frameworks, compilers,
 debuggers, and other tools you need to build apps that run natively on
 Apple Silicon 
\begin_inset CommandInset citation
LatexCommand citep
key "Apple-Xcode"
literal "false"

\end_inset

.
\end_layout

\begin_layout Subsection
Related Work
\end_layout

\begin_layout Standard
Over the last decade, there has been considerable progress in developing
 methodologies based in machine learning for many of Earth Science applications
 
\begin_inset CommandInset citation
LatexCommand citep
key "Lary2018"
literal "false"

\end_inset

.
 We present relevant articles related to the implementation of machine learning
 in the classifcation of images into the geoscience field.
\begin_inset Note Note
status collapsed

\begin_layout Plain Layout
In some of this articles I found about the 
\begin_inset Quotes eld
\end_inset

classification of rock lithology on geological surveys
\begin_inset Quotes erd
\end_inset

.
 However, I want to ask if it is a different type of rock classification
 than the used in this work.
 What do they mean by lithology?
\end_layout

\begin_layout Plain Layout
I searched in web but couldn´t understand.
 I just mentioned it in the articles below as rock classification.
\end_layout

\end_inset


\end_layout

\begin_layout Subsubsection
Rock lithology image classification using machine learning
\end_layout

\begin_layout Standard
In 
\begin_inset CommandInset citation
LatexCommand citep
key "Ran2019"
literal "false"

\end_inset

, Ran et al.
 also worked on the classification of rocks from images using machine learning.
 A total of 2,290 images with typical rock characteristics of six rock types
 (granite, limestone, conglomerate, sandstone, shale, mylonite) were used
 in the study.
 The images were labeled according to the clarity of the rock and were then
 cropped into 14,589 sample patches of 512 × 512 pixels compressed to 128
 × 128 pixels.
 60% of the patches of each type of rock were selected for the training
 dataset, 20% for the validation dataset, and 20% for the testing dataset.
 Finally, they proposed a deep CNN model that was compared with four machine
 learning models: SVM, AlexNet, GoogleLeNet Inception v3, and VGGNet-16.
 The proposed model achieved the highest overall accuracy of 97.76% compared
 with the other models.
\end_layout

\begin_layout Standard
In 
\begin_inset CommandInset citation
LatexCommand citep
key "Cheng2017"
literal "false"

\end_inset

, Cheng and Guo proposed a deep CNN to identify the rock granularity in
 images under three color spaces.
 The dataset contained 4,200 RGB images of feldspar sandstone rocks collected
 from an oil field in Ordos and divided into three types: coarse, medium
 granular, and fine feldspar sandstone.
 The images were normalized to 224 × 224 pixels and converted to YCbCr and
 HSV color spaces.
 The proposed CNN was a 6-layer structure: 4 convoluted layers with ReLU
 as the activation function and 2 fully connected layers with Softmax as
 the classifier.
 The model was trained for each color space with 75% of the experimental
 data, a batch size of 100, and different kernel sizes and learning rates.
 The lowest error rates were obtained with a learning rate of 0.0005, the
 kernel sizes of 11, 5, 3, and 3 for each convolutional layer respectively,
 and the cross-validation for HSV color space.
 In RGB color space, the classification accuracy achieved 98.5%.
\end_layout

\begin_layout Paragraph
Rock classification with machine learning on android devices
\end_layout

\begin_layout Standard
In 
\begin_inset CommandInset citation
LatexCommand citep
key "Fan2020"
literal "false"

\end_inset

, Fan et al.
 created a method for rock lithology recognition on android devices based
 on two lightweight CNNs.
 A total of 3,208 images taken by a smartphone camera were selected from
 the China Geological Survey dataset.
 The images of 28 rock categories were reduced to 214 × 214 pixels and the
 80% were used to train two CNNs pretrained with ImageNet dataset based
 on MobileNet and SqueezeNet models.
 The achieved occupation sizes were 19.6 M and 36.8 M for MobileNet and SqueezeNet
, and 232.7 M for a heavyweight ResNet50 model built to compare the models.
 SqueezeNet was almost two times faster than MobileNet, and 7 times faster
 than ResNet50.
 A rock recognition software based on the trained models was developed for
 Android devices.
 The results for SqueezeNet and MobileNet on android smartphones were as
 follows: the file sizes of 9.2 MB and 17.6 MB, the execution time from 736
 to 366 and 1,218 to 523 millisecond, and the recognition accuracies of
 94.55% and 93.27%.
\end_layout

\begin_layout Standard
In 
\begin_inset CommandInset citation
LatexCommand citep
key "Shoji2018"
literal "false"

\end_inset

, Shoji et al.
 constructed a machine learning model for quick and accurate rock lithology
 recognition with smartphones.
 A total of 3,795 images were taken to 30 different kinds of rocks collected
 from multiple locations in East China.
 A proposed model was trained using 80% of the dataset, 3,600 iteration
 steps, a learning rate of 0.008, and the parameters imported by the transfer
 learning method from the ShuffleNet model pretrained with the ImageNet
 dataset.
 After ShuffleNet was compared with MobileNet, SqueezeNet, and ResNet50.
 Each one occupied 34.5M, 18.2M, and 25M, and 219.4M respectively.
 An android application was created in Java programming language and run
 on three android smartphones (Huawei, Samsung, and Oppo).
 The accuracy of the recognition model based on ShuffleNet reached 97.65%
 in the verification data set of PC and 95.30% on the test data set of the
 smartphone.
 The average recognition time of a single rock image was 786 milliseconds
 and the model size was only 18.2 MB.
\end_layout

\begin_layout Standard
In [], the authors worked on the automatic classification of plutonic rocks
 in android devices.
 The dataset contained 71 images of diorite, gabbro, granite, granodiorite,
 monzodiorite, and tonalite which classification was based on petrographic
 analysis of Cretaceous granitoids collected from Peru.
 To increase the number of images, a new dataset of 846 patches from around
 450 × 700 to 900 × 1000 pixels was generated from the first dataset.
 A deep neural network was created with 4-layer structure: two convolutional,
 and two fully connected layers.
 After each convolutional layer it was a max pooling layer of 2×2 size,
 and a flatten and a dropout layers before the fisrt and second fully conected
 layers respectively.
 Several combinations of the rock classes were trained with 50% of the image
 patches, 100 epochs and a batch size of 32.
 The best combination was with four classes of plutonic rocks (gabbro, diorite,
 granite and granodiorite) achieving an accuracy of 95%, an average precision
 of 96%, an average recall of 95%, and an average F1-score of 95%.
 Finally, an android application was developed using the proposed model
 trained with the best combination of rocks.
 The application evaluation results were: 70% for gabbro, 28.5% for diorite,
 100% for granodiorite, and 28.5% for granite.
\end_layout

\begin_layout Subsubsection
Mineral images recognition with machine learning
\end_layout

\begin_layout Standard
In 
\begin_inset CommandInset citation
LatexCommand citep
key "Zhang2019"
literal "false"

\end_inset

, Zhang et al.
 worked on the intelligent identification for rock-mineral images using
 ensemble machine learning algorithms (model stacking).
 A total of 481 images of four minerals: K-feldspar (Kf), perthite (Pe),
 plagioclase (Pl), and quartz (Qz or Q) were obtained with the camera on
 the top of a microscope.
 The target RGB images were cropped to cover the minerals and then processed
 to be 299 × 299 pixels.
 A deep learning model based on Inception-v3 was adopted to extract high-level
 features from the images and train the LR, SVM, KNN, Random Forest (RF),
 Multilayer Perceptron (MLP), and Gaussian Naive Bayes (GNB) algorithms.
 LR, SVM, and MLP had a significant effect on extracted features, with higher
 accuracy (90.0%, 90.6%, and 89.8%) than the other models.
 The new features generated by this three models were employed for the model
 stacking in a new instance of LR.
 The stacking model showed a better performance than the single models,
 with an accuracy of 90.9%.
\end_layout

\begin_layout Standard
In 
\begin_inset CommandInset citation
LatexCommand citep
key "Maitre2019"
literal "false"

\end_inset

, Maitre et al.
 worked on the automated recognition of mineral grains based on supervised
 machine learning.
 A large mosaic RGB image was constructed with several views of a sample
 surface taken with a stereo-zoom binocular microscope.
 The sample surface contained grains of 27 different mineral species (plagioclas
e, augite, background, hypersthene, ilmenite, magnetite, titanite, hornblende,
 etc.) and was scanned with an automated Scanning Electron Microscopy (SEM)
 that assigned to each grain a mineral specie based on its chemical signature.
 Both images were divided in 3,192 sub-images of 600 × 600 pixels.
 To label the grains of the mosaic image, the simple linear iterative clustering
 (SLIC) algorithm was applied for superpixel segmentation to match each
 superpixel of the mosaic's sub-images with the superpixels of the SEM's
 scan sub-images.
 From the computed RGB superpixel histograms, the color intensity (quantile)
 and peak intensity (ratio between the number of pixels in the first and
 second maximum bins to total number of pixels) were extracted as features
 for each superpixels.
 KNN, RF, and Classification and Regression Trees (CART) algorithms were
 trained with 70% of the extracted features, and tested with the other 30%
 using the kappa statistics, precision, recall, and f1-score indicators.
 The RF algorithm gave the best results with a global accuracy of 89%.
\end_layout

\begin_layout Standard
As shown in the previously described articles, machine learning has been
 an accurate way for image classification in field of geosciences.
 Feature extraction was applied in 
\begin_inset CommandInset citation
LatexCommand citep
key "Maitre2019"
literal "false"

\end_inset

 and 
\begin_inset CommandInset citation
LatexCommand citep
key "Zhang2019"
literal "false"

\end_inset

 before the training of supervised machine learnign algorithms to classify
 mineral samples.
 These articles presented accuracies from around 90% and were trained with
 
\end_layout

\begin_layout Section
Results
\end_layout

\begin_layout Subsection
Methodology
\end_layout

\begin_layout Standard
This section details each of the steps followed to obtain the best machine
 learning algorithm for the mobile application.
\end_layout

\begin_layout Subsubsection
Data description
\end_layout

\begin_layout Standard
The original images were provided by the Department of Earth and Biological
 Sciences, Loma Linda University.
 The dataset contains images of four classes of plutonic rocks: granite,
 granodiorite, gabbro, and diorite with a total of 81 images.
 The images used in the following experiments are available online
\begin_inset Foot
status collapsed

\begin_layout Plain Layout
https://github.com/sarah-hs/Color-extraction/tree/main/Rock-images
\end_layout

\end_inset

.
 Table 1 shows the number of images per class.
\end_layout

\begin_layout Standard
\begin_inset Float table
wide false
sideways false
status collapsed

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Number of images per class
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
centering
\end_layout

\begin_layout Plain Layout


\backslash
renewcommand{
\backslash
arraystretch}{1.1}
\end_layout

\begin_layout Plain Layout


\backslash
newrobustcmd{
\backslash
B}{
\backslash
bfseries}
\end_layout

\begin_layout Plain Layout


\backslash
begin{tabular}{|l|*{5}{c|}}
\backslash
hline
\end_layout

\begin_layout Plain Layout


\backslash
makebox[7em]{
\backslash
B Class} &
\backslash
makebox[7em]{
\backslash
B Number of images}
\backslash

\backslash

\end_layout

\begin_layout Plain Layout


\backslash
hline
\end_layout

\begin_layout Plain Layout

Granite & 16 
\backslash

\backslash

\end_layout

\begin_layout Plain Layout


\backslash
hline
\end_layout

\begin_layout Plain Layout

Granodiorite & 21 
\backslash

\backslash

\end_layout

\begin_layout Plain Layout


\backslash
hline
\end_layout

\begin_layout Plain Layout

Gabbro & 19 
\backslash

\backslash

\end_layout

\begin_layout Plain Layout


\backslash
hline
\end_layout

\begin_layout Plain Layout

Diorite & 25 
\backslash

\backslash

\end_layout

\begin_layout Plain Layout


\backslash
hline
\end_layout

\begin_layout Plain Layout


\backslash
B Total of images & 
\backslash
B 81 
\backslash

\backslash

\end_layout

\begin_layout Plain Layout


\backslash
hline
\end_layout

\begin_layout Plain Layout


\backslash
end{tabular}
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Subsubsection
Data preparation
\end_layout

\begin_layout Standard
In this step the images were processed to extract the color values from
 image pixels.
 The notebook with the source code is available online
\begin_inset Foot
status collapsed

\begin_layout Plain Layout
http://bit.ly/3pyh3JL
\end_layout

\end_inset

.
 In listing 1, the 
\begin_inset Quotes eld
\end_inset

load_images_from_folder
\begin_inset Quotes erd
\end_inset

 function showed in lines 6 to 18, is declared to process all the files
 with image extension ('.png', ’.jpg’, ’.pge’) from a folder.
 It also crops the images to a given size as shown in line 13 because we
 need all images to be the same size to train the machine learning algorithms.
\end_layout

\begin_layout Standard
\begin_inset CommandInset include
LatexCommand lstinputlisting
filename "Code/load images from folder.txt"
lstparams "language=Python,caption={Function to load images from a folder},label={load images from folder}"

\end_inset


\end_layout

\begin_layout Standard
In listing 2, the 
\begin_inset Quotes eld
\end_inset

load_images_from_directory
\begin_inset Quotes erd
\end_inset

 function is declared from lines 1 to 13 to iterate the subfolders contained
 in a main directory and process the images in them with the support of
 the previous declared 
\begin_inset Quotes eld
\end_inset

load_images_from_folder
\begin_inset Quotes erd
\end_inset

 function.
 It also assigns labels to the processed images according to the name of
 the folder in which they are as shown in line 9.
 For that reason it is important to group the images in subfolders based
 on their rock class name.
\end_layout

\begin_layout Standard
Finally, in line 17, the rock images in the folder declared in line 15 are
 processed and cropped to the size declared in line 16.
\end_layout

\begin_layout Standard
\begin_inset CommandInset include
LatexCommand lstinputlisting
filename "Code/load images from directory.txt"
lstparams "language=Python,caption={Function to load images from a directory},label={load images from directory}"

\end_inset


\end_layout

\begin_layout Subsubsection
Determining the best k number of clusters
\end_layout

\begin_layout Standard
The k-means algorithm was used to extract the dominant colors from the images.
 First, it was necessary to calculate the optimal number of clusters (groups
 of pixels with similar color) to use in the algorithm.
 In listing 3, the Elbow method is used for this purpose.
 This method consists of iterating in a range of possible cluster numbers
 to use in the k-means algorithm and determine the best number.
 In lines 4 to 9 it is iterated a cluster range between 2 and 20, at each
 iteration k-means is trained with the image data declared in line 1 and
 one of the cluster numbers.
 In lines 11 to 16 the score obtained with each number of cluster is plotted
 
\shape italic
\emph on
(see Fig.
 
\shape default
\emph default
2) and the number on the elbow of the plot is the best k number of clusters.
 For this experiment that number is 4.
\end_layout

\begin_layout Standard
\begin_inset CommandInset include
LatexCommand lstinputlisting
filename "Code/elbow method.txt"
lstparams "language=Python,caption={Determining the best number of clusters with the Elbow method},label={elbow method}"

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status collapsed

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Images/Elbow curve.png
	lyxscale 30
	width 100col%

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
The Elbow method showing the optimal k number of clusters
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Subsubsection
Color extraction
\end_layout

\begin_layout Standard
This step describes the process for extracting the dominant colors from
 the rock images.
\end_layout

\begin_layout Standard
Finally, the dominant colors of an image are selected grouping the image
 pixels in a certain number of k groups according to their color in the
 RGB color space.
 The average color of each group are the dominant colors and the number
 of pixels of that groups are the dominant colors´ percentage.
\end_layout

\begin_layout Standard
In listing 4, the 
\begin_inset Quotes eld
\end_inset

get_dominant_colors
\begin_inset Quotes erd
\end_inset

 function was created.
 That function receives the pixel values of an image to train the k-means
 algorithm with 4 clusters, the number of clusters selected in the previous
 step.
 In line 6, k-means works by separating the pixels of that image into k
 groups (clusters) of similarly coloured pixels.
 The colors at each cluster center reflect the average of the attributes
 of all members of a cluster.
 The percentage of a cluster calculated in lines 8 to 10 is the number of
 pixels within that cluster.
 From lines 14 to 18 the center color in each cluster and its percentage
 is added to the features list that returns, in line 20, sixteen elements:
 the four main colors in RGB (red, green, and blue) color format and their
 percentage (see Fig.
 3).
\end_layout

\begin_layout Standard
\begin_inset CommandInset include
LatexCommand lstinputlisting
filename "Code/get dominant colors.txt"
lstparams "language=Python,caption={Function to extract the dominant colors from a single image},label={get dominant colors}"

\end_inset


\end_layout

\begin_layout Standard
In listing 5, the image data from the preparation step is iterated to extract
 the dominant colors with the previous explained 
\begin_inset Quotes eld
\end_inset

get_dominant_colors
\begin_inset Quotes erd
\end_inset

 function of listing 4.
 These colors are added to a new array called 
\begin_inset Quotes eld
\end_inset

extracted_colors
\begin_inset Quotes erd
\end_inset

.
 In line 6, the extracted colors are saved together with their respective
 rock label in a CSV file.
 This file is used in the next step to train the machine learning algorithms.
 The CSV is available online
\begin_inset Foot
status collapsed

\begin_layout Plain Layout
https://github.com/sarah-hs/Color-extraction/blob/main/colors.csv
\end_layout

\end_inset

.
\end_layout

\begin_layout Standard
\begin_inset CommandInset include
LatexCommand lstinputlisting
filename "Code/Iterate in data to extract colors.txt"
lstparams "language=Python,caption={Iterate original data to extract dominant colors},label={Iterate in data to extract colors}"

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status collapsed

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Images/Color extraction.png
	lyxscale 30
	width 100col%

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Dominant colors and average color of sample images
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Subsubsection
Training of the different algorithms
\end_layout

\begin_layout Standard
Five machine learning algorithms were trained for this experiment.
 They are Logistic Regression, K-Nearest Neighbors, Decision Trees, Support
 Vector Machines, and a Convolutional Neural Network.
 The notebook showing the training and validation process is also available
 online
\begin_inset Foot
status collapsed

\begin_layout Plain Layout
https://github.com/sarah-hs/Color-extraction/blob/main/ML-training.ipynb
\end_layout

\end_inset

.
\end_layout

\begin_layout Standard
First, in listing 6, the main dominant colors data is loaded from the CSV
 file of the previous step into x and y Numpy arrays and splitted into train,
 test and validation sets.
 The 
\begin_inset Quotes eld
\end_inset

train_test_split
\begin_inset Quotes erd
\end_inset

 function was used in line 9 to split the data and get a validation set
 with 20% of the data.
 In line 10, the other 80% of the split in line 9 was splitted again in
 20% for the test set and 80% for the train set.
 Three sets were used in the experiments: 20% for validation, 16% for testing,
 and 64% for training from the total of the data.
 The train set (
\begin_inset Quotes eld
\end_inset

xtrain
\begin_inset Quotes erd
\end_inset

 and 
\begin_inset Quotes eld
\end_inset

ytrain
\begin_inset Quotes erd
\end_inset

) was used to train all the algorithms.
\end_layout

\begin_layout Standard
\begin_inset CommandInset include
LatexCommand lstinputlisting
filename "Code/split data.txt"
lstparams "language=Python,caption={Splitting the data in train and test},label={split data in test and train}"

\end_inset


\end_layout

\begin_layout Standard
Below, listing 7 presents the training process and the parameters used for
 each algorithm.
\end_layout

\begin_layout Standard
Logistic Regression utilize in line 3 the Limited-memory Broyden–Fletcher–Goldfa
rb–Shanno (L-BFGS) solver parameter.
 This optimizer starts iterating at a random point (xt) to calculate a new
 point (xt+1) that is the minimum from the second derivate of original function
 at the starting point (xt).
 The new point will become the starting point for the next iteration.
 In this way, L-BFGS quickly converges on the solution 
\begin_inset CommandInset citation
LatexCommand citep
key "Dangeti2017"
literal "false"

\end_inset

.
\end_layout

\begin_layout Standard
K-Nearest-Neighbors was declared in line 8 with 3 n_neighbors.
 This number represents the number of neighbors used to classify a new sample
 into the class to which most of the neighbors belong.
\end_layout

\begin_layout Standard
Decision Trees algorithm was tuned specifying the class weights as 'balanced'
 in line 13.
 By utilizing class weights, we can increase the importance of a particular
 class and the balanced mode in class weight parameter uses the values of
 ytrain to automatically adjust the node weights inversely proportional
 to the class frequencies in the input data 
\begin_inset CommandInset citation
LatexCommand citep
key "Dangeti2017"
literal "false"

\end_inset

.
\end_layout

\begin_layout Standard
Support Vector Machines in line 18 was created with the Radial Basis Function
 (RBF) kernel to eliminate the computational requirement of the algorithm.
 Also the gamma value is used to scale the features when using the RBF kernel.
 This is very important because small gamma will give you low bias and high
 variance solutions.
 The 'auto' paramater is a small gamma represented by 
\begin_inset Formula $1/numberOfFeatures$
\end_inset

 
\begin_inset CommandInset citation
LatexCommand citep
key "Dangeti2017"
literal "false"

\end_inset

.
\end_layout

\begin_layout Standard
The Convolutional Neural Network was build as shown in lines 29 to 37.
 It was used two convolutional layers of one dimension with 32 filters and
 a kernel size of 2x2 in lines 29 and 30, a dropout layer of 50% in line
 31, a one dimension max pooling layer of 2x2 in line 32, and two fully
 connected layers in lines 34 and 35 with 100 connections the fisrt layer
 and the second with the number of rock classes used in this project that
 is 4.
 The model was compiled in line 36 with the ’categorical_crossentropy’ loss
 function used for categorical problem with more than 2 classes, and the
 'Adam' optimizer an computationally efficient optimization algorithm.
\end_layout

\begin_layout Standard
The training of each algortihm is listed in lines 4, 9, 14, 19, and 37 respectiv
ely.
 In order to train the convolutional neural network, it was necessary to
 try with several numbers of epochs and batches until the most optimal values
 were obtained as shown in line 37.
\end_layout

\begin_layout Standard
\begin_inset CommandInset include
LatexCommand lstinputlisting
filename "Code/train models.txt"
lstparams "language=Python,caption={Normalizing data and training models},label={train models}"

\end_inset


\end_layout

\begin_layout Subsubsection
Evaluation of the algorithms
\end_layout

\begin_layout Standard
Evaluating a model is a core part of building an effective machine learning
 project.
 For this purpose are used the following four metrics to evaluate the algorithms
 
\begin_inset CommandInset citation
LatexCommand citep
key "Mishra2018"
literal "false"

\end_inset

:
\end_layout

\begin_layout Itemize
Accuracy is the ratio of number of correct predictions to the total number
 of input samples.
\begin_inset Formula 
\[
Accuracy=\frac{CorrectPredictions}{PredictionsMade}
\]

\end_inset


\end_layout

\begin_layout Itemize
Precision is the number of correct positive results divided by the number
 of positive results predicted by the classifier.
\begin_inset Formula 
\[
Precision=\frac{TP}{TP+FP}
\]

\end_inset


\end_layout

\begin_layout Itemize
Recall is the number of correct positive results divided by the number of
 all relevant samples (all samples that should have been identified as positive).
 
\begin_inset Formula 
\[
Recall=\frac{TP}{TP+FN}
\]

\end_inset


\end_layout

\begin_layout Itemize
F1-score is used to measure a test’s accuracy, the Harmonic Mean between
 precision and recall.
 It tells you how precise your classifier is (how many instances it classifies
 correctly), as well as how robust it is (it does not miss a significant
 number of instances).
\begin_inset Formula 
\[
F1=2*\frac{Precision*Recall}{Precision+Recall}
\]

\end_inset

The greater the F1-score, the better is the performance of our model.
\end_layout

\begin_layout Standard
Table 2 shows the accuracy of all the trained algorithms evaluated with
 the test set of the previous step.
\end_layout

\begin_layout Standard
\begin_inset Float table
wide false
sideways false
status collapsed

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Results of the algorithms in terms of accuracy
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
centering
\end_layout

\begin_layout Plain Layout


\backslash
renewcommand{
\backslash
arraystretch}{1.1}
\end_layout

\begin_layout Plain Layout


\backslash
newrobustcmd{
\backslash
B}{
\backslash
bfseries}
\end_layout

\begin_layout Plain Layout


\backslash
begin{tabular}{|l|*{2}{c|}}
\backslash
hline
\end_layout

\begin_layout Plain Layout


\backslash
makebox[8em]{
\backslash
B Model} &
\backslash
makebox[3.5em]{
\backslash
B Accuracy} 
\backslash

\backslash

\end_layout

\begin_layout Plain Layout


\backslash
hline
\end_layout

\begin_layout Plain Layout

Logistic Regression & 0.29 
\backslash

\backslash

\end_layout

\begin_layout Plain Layout


\backslash
hline
\end_layout

\begin_layout Plain Layout

K-Nearest Neighbors & 0.82 
\backslash

\backslash

\end_layout

\begin_layout Plain Layout


\backslash
hline
\end_layout

\begin_layout Plain Layout

Decision Trees & 0.70 
\backslash

\backslash

\end_layout

\begin_layout Plain Layout


\backslash
hline
\end_layout

\begin_layout Plain Layout

Support Vector Machine & 0.41 
\backslash

\backslash

\end_layout

\begin_layout Plain Layout


\backslash
hline
\end_layout

\begin_layout Plain Layout

Convolutional Neural Network & 0.41 
\backslash

\backslash

\end_layout

\begin_layout Plain Layout


\backslash
hline
\end_layout

\begin_layout Plain Layout


\backslash
B Average & 
\backslash
B 0.52 
\backslash

\backslash

\end_layout

\begin_layout Plain Layout


\backslash
hline
\end_layout

\begin_layout Plain Layout


\backslash
end{tabular}
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
Tables 3-7 show the results of each model evaluation in terms of precision,
 recall and F1-score.
\end_layout

\begin_layout Standard
\begin_inset Float table
wide false
sideways false
status collapsed

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Results of Logistic Regression
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
centering
\end_layout

\begin_layout Plain Layout


\backslash
renewcommand{
\backslash
arraystretch}{1.1}
\end_layout

\begin_layout Plain Layout


\backslash
newrobustcmd{
\backslash
B}{
\backslash
bfseries}
\end_layout

\begin_layout Plain Layout


\backslash
begin{tabular}{|l|*{4}{c|}}
\backslash
hline
\end_layout

\begin_layout Plain Layout


\backslash
makebox[5em]{
\backslash
B Class} &
\backslash
makebox[5em]{
\backslash
B Precision} &
\backslash
makebox[5em]{
\backslash
B Recall} &
\backslash
makebox[5em]{
\backslash
B F1-Score}
\backslash

\backslash

\end_layout

\begin_layout Plain Layout


\backslash
hline
\end_layout

\begin_layout Plain Layout

Granite & 1.00 & 1.00 & 1.00 
\backslash

\backslash

\end_layout

\begin_layout Plain Layout


\backslash
hline
\end_layout

\begin_layout Plain Layout

Granodiorite & 0.86 & 1.00 & 0.92 
\backslash

\backslash

\end_layout

\begin_layout Plain Layout


\backslash
hline
\end_layout

\begin_layout Plain Layout

Gabbro &  0.50 & 1.00 & 0.67 
\backslash

\backslash

\end_layout

\begin_layout Plain Layout


\backslash
hline
\end_layout

\begin_layout Plain Layout

Diorite & 1.00 & 0.57 & 0.73 
\backslash

\backslash

\end_layout

\begin_layout Plain Layout


\backslash
hline
\end_layout

\begin_layout Plain Layout


\backslash
B Average & 
\backslash
B 0.84 & 
\backslash
B 0.89 & 
\backslash
B 0.83 
\backslash

\backslash

\end_layout

\begin_layout Plain Layout


\backslash
hline
\end_layout

\begin_layout Plain Layout


\backslash
end{tabular}
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Float table
wide false
sideways false
status collapsed

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Results of K-Nearest Neighbors
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
centering
\end_layout

\begin_layout Plain Layout


\backslash
renewcommand{
\backslash
arraystretch}{1.1}
\end_layout

\begin_layout Plain Layout


\backslash
newrobustcmd{
\backslash
B}{
\backslash
bfseries}
\end_layout

\begin_layout Plain Layout


\backslash
begin{tabular}{|l|*{4}{c|}}
\backslash
hline
\end_layout

\begin_layout Plain Layout


\backslash
makebox[5em]{
\backslash
B Class} &
\backslash
makebox[5em]{
\backslash
B Precision} &
\backslash
makebox[5em]{
\backslash
B Recall} &
\backslash
makebox[5em]{
\backslash
B F1-Score}
\backslash

\backslash

\end_layout

\begin_layout Plain Layout


\backslash
hline
\end_layout

\begin_layout Plain Layout

Granite & 1.00 & 1.00 & 1.00 
\backslash

\backslash

\end_layout

\begin_layout Plain Layout


\backslash
hline
\end_layout

\begin_layout Plain Layout

Granodiorite & 0.86 & 1.00 & 0.92 
\backslash

\backslash

\end_layout

\begin_layout Plain Layout


\backslash
hline
\end_layout

\begin_layout Plain Layout

Gabbro & 0.50 & 1.00 & 0.67 
\backslash

\backslash

\end_layout

\begin_layout Plain Layout


\backslash
hline
\end_layout

\begin_layout Plain Layout

Diorite & 1.00 & 0.57 & 0.73 
\backslash

\backslash

\end_layout

\begin_layout Plain Layout


\backslash
hline
\end_layout

\begin_layout Plain Layout


\backslash
B Average & 
\backslash
B 0.84 & 
\backslash
B 0.89 & 
\backslash
B 0.83 
\backslash

\backslash

\end_layout

\begin_layout Plain Layout


\backslash
hline
\end_layout

\begin_layout Plain Layout


\backslash
end{tabular}
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Float table
wide false
sideways false
status collapsed

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Results of Decision Trees
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
centering
\end_layout

\begin_layout Plain Layout


\backslash
renewcommand{
\backslash
arraystretch}{1.1}
\end_layout

\begin_layout Plain Layout


\backslash
newrobustcmd{
\backslash
B}{
\backslash
bfseries}
\end_layout

\begin_layout Plain Layout


\backslash
begin{tabular}{|l|*{4}{c|}}
\backslash
hline
\end_layout

\begin_layout Plain Layout


\backslash
makebox[5em]{
\backslash
B Class} &
\backslash
makebox[5em]{
\backslash
B Precision} &
\backslash
makebox[5em]{
\backslash
B Recall} &
\backslash
makebox[5em]{
\backslash
B F1-Score}
\backslash

\backslash

\end_layout

\begin_layout Plain Layout


\backslash
hline
\end_layout

\begin_layout Plain Layout

Granite & 1.00 & 0.50 & 0.67 
\backslash

\backslash

\end_layout

\begin_layout Plain Layout


\backslash
hline
\end_layout

\begin_layout Plain Layout

Granodiorite & 0.62 & 0.83 & 0.71 
\backslash

\backslash

\end_layout

\begin_layout Plain Layout


\backslash
hline
\end_layout

\begin_layout Plain Layout

Gabbro & 1.00 & 1.00 & 1.00 
\backslash

\backslash

\end_layout

\begin_layout Plain Layout


\backslash
hline
\end_layout

\begin_layout Plain Layout

Diorite & 0.67 & 0.57 & 0.62 
\backslash

\backslash

\end_layout

\begin_layout Plain Layout


\backslash
hline
\end_layout

\begin_layout Plain Layout


\backslash
B Average & 
\backslash
B 0.82 & 
\backslash
B 0.73 & 
\backslash
B 0.75 
\backslash

\backslash

\end_layout

\begin_layout Plain Layout


\backslash
hline
\end_layout

\begin_layout Plain Layout


\backslash
end{tabular}
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Float table
wide false
sideways false
status collapsed

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Results of Support Vector Machine
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
centering
\end_layout

\begin_layout Plain Layout


\backslash
renewcommand{
\backslash
arraystretch}{1.1}
\end_layout

\begin_layout Plain Layout


\backslash
newrobustcmd{
\backslash
B}{
\backslash
bfseries}
\end_layout

\begin_layout Plain Layout


\backslash
begin{tabular}{|l|*{4}{c|}}
\backslash
hline
\end_layout

\begin_layout Plain Layout


\backslash
makebox[5em]{
\backslash
B Class} &
\backslash
makebox[5em]{
\backslash
B Precision} &
\backslash
makebox[5em]{
\backslash
B Recall} &
\backslash
makebox[5em]{
\backslash
B F1-Score}
\backslash

\backslash

\end_layout

\begin_layout Plain Layout


\backslash
hline
\end_layout

\begin_layout Plain Layout

Granite & 0.50 & 0.50 & 0.50 
\backslash

\backslash

\end_layout

\begin_layout Plain Layout


\backslash
hline
\end_layout

\begin_layout Plain Layout

Granodiorite & 0.40 & 0.67 & 0.50 
\backslash

\backslash

\end_layout

\begin_layout Plain Layout


\backslash
hline
\end_layout

\begin_layout Plain Layout

Gabbro & 0.40 & 1.00 & 0.57 
\backslash

\backslash

\end_layout

\begin_layout Plain Layout


\backslash
hline
\end_layout

\begin_layout Plain Layout

Diorite & 0.00 & 0.00 & 0.00 
\backslash

\backslash

\end_layout

\begin_layout Plain Layout


\backslash
hline
\end_layout

\begin_layout Plain Layout


\backslash
B Average & 
\backslash
B 0.33 & 
\backslash
B 0.54 & 
\backslash
B 0.39 
\backslash

\backslash

\end_layout

\begin_layout Plain Layout


\backslash
hline
\end_layout

\begin_layout Plain Layout


\backslash
end{tabular}
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Float table
wide false
sideways false
status collapsed

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Results of Convolutional Neural Network
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
centering
\end_layout

\begin_layout Plain Layout


\backslash
renewcommand{
\backslash
arraystretch}{1.1}
\end_layout

\begin_layout Plain Layout


\backslash
newrobustcmd{
\backslash
B}{
\backslash
bfseries}
\end_layout

\begin_layout Plain Layout


\backslash
begin{tabular}{|l|*{4}{c|}}
\backslash
hline
\end_layout

\begin_layout Plain Layout


\backslash
makebox[5em]{
\backslash
B Class} &
\backslash
makebox[5em]{
\backslash
B Precision} &
\backslash
makebox[5em]{
\backslash
B Recall} &
\backslash
makebox[5em]{
\backslash
B F1-Score}
\backslash

\backslash

\end_layout

\begin_layout Plain Layout


\backslash
hline
\end_layout

\begin_layout Plain Layout

Granite & 0.00 & 0.00 & 0.00 
\backslash

\backslash

\end_layout

\begin_layout Plain Layout


\backslash
hline
\end_layout

\begin_layout Plain Layout

Granodiorite & 0.42 & 0.83 & 0.56 
\backslash

\backslash

\end_layout

\begin_layout Plain Layout


\backslash
hline
\end_layout

\begin_layout Plain Layout

Gabbro & 0.40 & 1.00 & 0.57 
\backslash

\backslash

\end_layout

\begin_layout Plain Layout


\backslash
hline
\end_layout

\begin_layout Plain Layout

Diorite & 0.00 & 0.00 & 0.00 
\backslash

\backslash

\end_layout

\begin_layout Plain Layout


\backslash
hline
\end_layout

\begin_layout Plain Layout


\backslash
B Average & 
\backslash
B 0.20 & 
\backslash
B 0.46 & 
\backslash
B 0.28 
\backslash

\backslash

\end_layout

\begin_layout Plain Layout


\backslash
hline
\end_layout

\begin_layout Plain Layout


\backslash
end{tabular}
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Subsection
Results
\end_layout

\begin_layout Standard
This section cover the creation process of a mobile application that classifies
 four types of plutonic rocks with the dominant colors extracted from images
 taken on iOS devices.
 
\end_layout

\begin_layout Standard
As it is shown in the 
\begin_inset Quotes eld
\end_inset

evaluation of the algorithms
\begin_inset Quotes erd
\end_inset

 step from methodology, the algorithm with the best evaluation results was
 K-Nearest Neighbors.
 It was the algorithm implemented in the mobile application.
\end_layout

\begin_layout Standard
To develope the iOS application were used the following pod dependencies:
\end_layout

\begin_layout Itemize
The TensorFlowLite pod from Tensorflow is a dependency that allows to read
 an exported machine learning model from a 'tflite' file when the application
 starts.
 This way, the model can be used for classification.
\end_layout

\begin_layout Itemize
An adaptation of the DominantColor pod from Indragie Karunaratne.
 This dependency implements K-means algorithm to extract the dominant colors
 of new images in real-time with Swift, the language to develope iOS and
 macOS applications.
 It allows the exported model to classify rocks with the dominant colors.
\end_layout

\begin_layout Standard
The application works the classification with three main Swift files: ViewContro
ller.swift, ImageClassifier.swift, and DominantColors.swift.
 The source code of the application is available online
\begin_inset Foot
status collapsed

\begin_layout Plain Layout
https://github.com/sarah-hs/Rock-Classifer-iOS
\end_layout

\end_inset

.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement t
wide true
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Images/Workflow.png
	lyxscale 50
	width 80page%

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Application workflow
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Paragraph
View controller
\end_layout

\begin_layout Standard
This file is the link between the user view and the ImageClassifier class.
\end_layout

\begin_layout Standard
The following variables were used in the ViewController visualize the image
 and send it to the .
\end_layout

\begin_layout Standard
\begin_inset CommandInset include
LatexCommand lstinputlisting
filename "Code/ViewController.txt"
lstparams "escapeinside={*}{*},language=bash,morekeywords={class, static, enum,typealias,private,var,guard,func,init,self,try,switch,fileprivate},keywordsprefix={@},caption={ViewController.swift},label={View Controller}"

\end_inset


\end_layout

\begin_layout Paragraph
Image classifier
\end_layout

\begin_layout Standard
As shown in listing 9...
\end_layout

\begin_layout Standard
\begin_inset CommandInset include
LatexCommand lstinputlisting
filename "Code/ImageClassifier.txt"
lstparams "escapeinside={*}{*},language=bash,morekeywords={class, static, enum,typealias,private,var,guard,func,init,self,try,switch,fileprivate},keywordsprefix={@},caption={ImageClassifier.swift},label={Image Classifier}"

\end_inset


\end_layout

\begin_layout Paragraph
Dominant colors
\end_layout

\begin_layout Standard
HEre was used a function..
\end_layout

\begin_layout Standard
\begin_inset CommandInset include
LatexCommand lstinputlisting
filename "Code/DominantColors.txt"
lstparams "escapeinside={*}{*},language=bash,morekeywords={class, static, enum,typealias,private,var,guard,func,init,self,try,switch,fileprivate},keywordsprefix={@},caption={DominantColors.swift},label={Dominant Colors}"

\end_inset


\end_layout

\begin_layout Subsection
Discussion
\end_layout

\begin_layout Standard
Five machine learning algorithms were trained with just the four dominant
 colors extracted from rock images.
 The best algorithm in this experiment was K-Nearest Neighbors with an accuracy
 of 82%.
 Its values for precision, recall, and F1 score were 84%, 89%, and 83%.
 After obtain the best suited algorithm for rock classification with dominant
 colors, an iOS mobile application was developed to classify rock images
 into four classes of plutonic rocks (granite, granodioorite, gabbro and
 diorite).
 This application also allows the user to visualize the dominant colors
 and the average color in new images and detect changes in rock colors.
\end_layout

\begin_layout Section
Conclusions and Future Work
\end_layout

\begin_layout Standard
\begin_inset Note Note
status collapsed

\begin_layout Plain Layout
\begin_inset Newpage clearpage
\end_inset


\end_layout

\end_inset


\begin_inset Note Note
status collapsed

\begin_layout Plain Layout
\begin_inset Newpage pagebreak
\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset CommandInset bibtex
LatexCommand bibtex
btprint "btPrintCited"
bibfiles "Rocks"
options "bibtotoc"

\end_inset


\end_layout

\end_body
\end_document
